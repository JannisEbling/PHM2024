{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# from bench_functions import micha, rose\n",
    "# from botorch_gp import BotorchGp\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model_directory = \"C:/Projects/covnet2\"\n",
    "sys.path.append(model_directory)\n",
    "from model import Model\n",
    "from config import configs\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_samples(train_inputs, input, n):\n",
    "    distances = np.linalg.norm(train_inputs - input, axis=1)\n",
    "\n",
    "    # Get the indices of the 1000 smallest distances\n",
    "    closest_indices = np.argsort(distances)[:n]\n",
    "\n",
    "    # Select the 1000 closest samples\n",
    "    return closest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.read_csv(\"Data/X_train.csv\")\n",
    "y = pd.read_csv(\"Data/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"Data/X_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trq_measured</th>\n",
       "      <th>oat</th>\n",
       "      <th>mgt</th>\n",
       "      <th>pa</th>\n",
       "      <th>ias</th>\n",
       "      <th>np</th>\n",
       "      <th>ng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>76.2</td>\n",
       "      <td>29.50</td>\n",
       "      <td>648.0</td>\n",
       "      <td>303.2760</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>99.83</td>\n",
       "      <td>96.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>63.3</td>\n",
       "      <td>18.75</td>\n",
       "      <td>595.4</td>\n",
       "      <td>464.8200</td>\n",
       "      <td>96.5625</td>\n",
       "      <td>100.01</td>\n",
       "      <td>93.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>87.3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>644.4</td>\n",
       "      <td>503.5296</td>\n",
       "      <td>119.4375</td>\n",
       "      <td>99.92</td>\n",
       "      <td>96.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>630.7</td>\n",
       "      <td>458.4192</td>\n",
       "      <td>121.2500</td>\n",
       "      <td>100.04</td>\n",
       "      <td>96.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>73.1</td>\n",
       "      <td>21.25</td>\n",
       "      <td>625.9</td>\n",
       "      <td>626.3640</td>\n",
       "      <td>111.4375</td>\n",
       "      <td>100.17</td>\n",
       "      <td>95.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  trq_measured    oat    mgt        pa       ias      np     ng\n",
       "0   0          76.2  29.50  648.0  303.2760    0.0000   99.83  96.77\n",
       "1   1          63.3  18.75  595.4  464.8200   96.5625  100.01  93.61\n",
       "2   2          87.3   2.50  644.4  503.5296  119.4375   99.92  96.87\n",
       "3   3          85.4   0.25  630.7  458.4192  121.2500  100.04  96.04\n",
       "4   4          73.1  21.25  625.9  626.3640  111.4375  100.17  95.67"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trq_measured</th>\n",
       "      <th>oat</th>\n",
       "      <th>mgt</th>\n",
       "      <th>pa</th>\n",
       "      <th>ias</th>\n",
       "      <th>np</th>\n",
       "      <th>ng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54.100</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>544.5000</td>\n",
       "      <td>212.1408</td>\n",
       "      <td>74.56250</td>\n",
       "      <td>89.18000</td>\n",
       "      <td>99.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>49.625</td>\n",
       "      <td>24.22231</td>\n",
       "      <td>578.4844</td>\n",
       "      <td>1625.6400</td>\n",
       "      <td>30.35596</td>\n",
       "      <td>99.55273</td>\n",
       "      <td>91.3866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52.000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>566.1000</td>\n",
       "      <td>1912.9250</td>\n",
       "      <td>65.62500</td>\n",
       "      <td>100.14000</td>\n",
       "      <td>90.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62.400</td>\n",
       "      <td>7.25000</td>\n",
       "      <td>560.1000</td>\n",
       "      <td>277.0632</td>\n",
       "      <td>54.81250</td>\n",
       "      <td>90.64000</td>\n",
       "      <td>100.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>62.900</td>\n",
       "      <td>23.25000</td>\n",
       "      <td>593.7000</td>\n",
       "      <td>53.6448</td>\n",
       "      <td>73.43750</td>\n",
       "      <td>99.91000</td>\n",
       "      <td>92.1700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  trq_measured       oat       mgt         pa       ias         np  \\\n",
       "0   0        54.100   2.00000  544.5000   212.1408  74.56250   89.18000   \n",
       "1   1        49.625  24.22231  578.4844  1625.6400  30.35596   99.55273   \n",
       "2   2        52.000   7.00000  566.1000  1912.9250  65.62500  100.14000   \n",
       "3   3        62.400   7.25000  560.1000   277.0632  54.81250   90.64000   \n",
       "4   4        62.900  23.25000  593.7000    53.6448  73.43750   99.91000   \n",
       "\n",
       "         ng  \n",
       "0   99.6400  \n",
       "1   91.3866  \n",
       "2   90.9600  \n",
       "3  100.2800  \n",
       "4   92.1700  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>faulty</th>\n",
       "      <th>trq_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.717745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.791863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.944871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.322404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  faulty  trq_margin\n",
       "0   0       1  -13.717745\n",
       "1   1       0    1.791863\n",
       "2   2       1  -13.944871\n",
       "3   3       0   -0.017281\n",
       "4   4       0    7.322404"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = X[\"id\"]\n",
    "X_train = X.drop(\"id\", axis=1)\n",
    "X_test = X_test.drop(\"id\", axis=1)\n",
    "\n",
    "y_trq = y[\"trq_margin\"]\n",
    "y_faulty = y[\"faulty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_trq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "y_trq_np = np.array(y_trq)\n",
    "y_faulty_np = np.array(y_faulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train = X_np[:700000]\n",
    "exp_test = X_np[700000:700010]\n",
    "exp_y_train = y_trq_np[:700000]\n",
    "exp_y_test = y_trq_np[700000:700010]\n",
    "exp_yclass_train = y_faulty_np[:700000]\n",
    "exp_yclass_test = y_faulty_np[700000:700010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    1\n",
       "4    1\n",
       "6    1\n",
       "0    1\n",
       "2    1\n",
       "5    1\n",
       "7    1\n",
       "3    1\n",
       "8    1\n",
       "1    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "n_clusters=10\n",
    "X_scaled = scaler.fit_transform(exp_train)\n",
    "X_test_scaled = scaler.transform(exp_test)\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(X_test_scaled)\n",
    "\n",
    "# Get centroids and predict clusters\n",
    "centroids = kmeans.cluster_centers_\n",
    "cluster_labels = kmeans.predict(X_test_scaled)\n",
    "pd.Series(cluster_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 29.20it/s, loss=-0.706, lr=1.000E-03, noise=8.27e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[0.3066]], dtype=torch.float64)\n",
      "tensor([[0.2501]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0218]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 33.06it/s, loss=0.345, lr=1.000E-03, noise=1.69e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[7.4073]], dtype=torch.float64)\n",
      "tensor([[0.5052]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0083]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 33.90it/s, loss=0.0671, lr=1.000E-03, noise=0.00109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[-73.8771]], dtype=torch.float64)\n",
      "tensor([[0.0395]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0028]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 34.78it/s, loss=-0.728, lr=1.000E-03, noise=0.000347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[-19.3507]], dtype=torch.float64)\n",
      "tensor([[0.1019]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0007]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 33.90it/s, loss=1.14, lr=1.000E-03, noise=3.9e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[-2.4254]], dtype=torch.float64)\n",
      "tensor([[2.0503]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0138]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 33.90it/s, loss=-0.012, lr=1.000E-03, noise=1.14e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[2.0931]], dtype=torch.float64)\n",
      "tensor([[0.6074]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0047]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 31.25it/s, loss=-0.304, lr=1.000E-03, noise=9.48e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[9.9885]], dtype=torch.float64)\n",
      "tensor([[0.5094]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0033]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 34.48it/s, loss=0.144, lr=1.000E-03, noise=2.52e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[1.5706]], dtype=torch.float64)\n",
      "tensor([[0.8328]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0039]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 33.61it/s, loss=0.158, lr=1.000E-03, noise=2.95e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[17.3430]], dtype=torch.float64)\n",
      "tensor([[0.5749]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0073]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:00<00:00, 33.90it/s, loss=-0.327, lr=1.000E-03, noise=1.43e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[6.9612]], dtype=torch.float64)\n",
      "tensor([[0.0162]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0006]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "cluster_labels_series = pd.Series(cluster_labels)\n",
    "for i in range(n_clusters):\n",
    "    indices = cluster_labels_series == i\n",
    "    batch = X_test_scaled[indices]\n",
    "    centroid = centroids[i]\n",
    "    train_indices = get_closest_samples(X_scaled, centroid, 500)\n",
    "    #for j in range(10):\n",
    "    model = Model(X_scaled[train_indices], exp_y_train[train_indices], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "    model.fit(epochs=4, verbose=True)\n",
    "    torch.save(model, f'models/model_test.pth')\n",
    "    predictions= []\n",
    "    y_true=exp_y_test[indices]\n",
    "\n",
    "    loaded_model = torch.load(f'models/model_test.pth')\n",
    "    y_pred, lcb, ucb = loaded_model.predict(batch, pred_var=True)\n",
    "    predictions.append(y_pred.cpu())\n",
    "    print(f\"Prediction: {y_pred}\")\n",
    "    print(ucb-y_pred)\n",
    "    print(f\"real_value_error: {y_pred-torch.tensor(y_true).view(-1,1)}\")\n",
    "    del loaded_model\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_np)\n",
    "X_test_scaled = scaler.transform(X_test_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\janni\\AppData\\Local\\Temp\\ipykernel_19108\\727084103.py\", line 9, in <module>\n",
      "    model = Model(X_scaled[train_indices], y_trq_np[train_indices], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
      "  File \"C:\\Projects/covnet2\\model.py\", line 19, in __init__\n",
      "    from pt.models import CovNet\n",
      "  File \"C:\\Projects/covnet2\\pt\\models.py\", line 1, in <module>\n",
      "    from botorch.models.utils.gpytorch_modules import MIN_INFERRED_NOISE_LEVEL\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\botorch\\__init__.py\", line 7, in <module>\n",
      "    import gpytorch.settings as gp_settings\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\__init__.py\", line 5, in <module>\n",
      "    import linear_operator\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\__init__.py\", line 2, in <module>\n",
      "    from . import beta_features, operators, settings, utils\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\__init__.py\", line 3, in <module>\n",
      "    from ._linear_operator import LinearOperator, to_dense\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py\", line 27, in <module>\n",
      "    from .. import settings, utils\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\__init__.py\", line 4, in <module>\n",
      "    from .contour_integral_quad import contour_integral_quad\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\contour_integral_quad.py\", line 7, in <module>\n",
      "    from .linear_cg import linear_cg\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\linear_cg.py\", line 8, in <module>\n",
      "    from .deprecation import bool_compat\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\deprecation.py\", line 13, in <module>\n",
      "    bool_compat = (torch.ones(1) > 0).dtype\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\deprecation.py:13: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  bool_compat = (torch.ones(1) > 0).dtype\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:257: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n"
     ]
    }
   ],
   "source": [
    "all_predictions=[]\n",
    "\n",
    "for sample in X_test_scaled[20000:]:\n",
    "\n",
    "    train_indices = get_closest_samples(X_scaled, sample, 500)\n",
    "    predictions= []\n",
    "    for j in range(10):\n",
    "        try:\n",
    "            model = Model(X_scaled[train_indices], y_trq_np[train_indices], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "            model.fit(epochs=4, verbose=False)\n",
    "            y_pred= model.predict(sample)\n",
    "            predictions.append(y_pred.cpu())\n",
    "            del model\n",
    "        except:\n",
    "            predictions.append(False)\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "import pickle\n",
    "with open('predictions/y_pred_reg_20000_end.pkl', 'wb') as f:\n",
    "    pickle.dump(all_predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions/y_pred_reg_1000.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predictions/y_pred_reg_1000.pkl', 'rb') as f:\n",
    "    array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closer_to_zero(a, b):\n",
    "    if abs(a) < abs(b):\n",
    "        return a,1\n",
    "    else:\n",
    "        return b,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [01:03<00:00, 63.94s/it, loss=9.74, lr=1.000E-03, noise=1e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4411935125000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 23\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# model = Model(X_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# model.fit(epochs=epochs, verbose=False)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(y_pred)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# print(y_pred_2)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m---> 23\u001b[0m     y_pred, lcb, ucb \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_pred)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(ucb\u001b[38;5;241m-\u001b[39my_pred)\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\model.py:39\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, pred_var)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predict\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_var\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet backend name to \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m or  \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m in config.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\models.py:344\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, x, pred_var)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), settings\u001b[38;5;241m.\u001b[39mfast_pred_var():\n\u001b[1;32m--> 344\u001b[0m         posterior \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pred_var:\n\u001b[0;32m    346\u001b[0m             lower, upper \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mmvn\u001b[38;5;241m.\u001b[39mconfidence_region()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\botorch\\models\\gpytorch.py:399\u001b[0m, in \u001b[0;36mBatchedMultiOutputGPyTorchModel.posterior\u001b[1;34m(self, X, output_indices, observation_noise, posterior_transform)\u001b[0m\n\u001b[0;32m    393\u001b[0m     X, output_dim_idx \u001b[38;5;241m=\u001b[39m add_output_dim(\n\u001b[0;32m    394\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, original_batch_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_batch_shape\n\u001b[0;32m    395\u001b[0m     )\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# NOTE: BoTorch's GPyTorchModels also inherit from GPyTorch's ExactGP, thus\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;66;03m# self(X) calls GPyTorch's ExactGP's __call__, which computes the posterior,\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# rather than e.g. SingleTaskGP's forward, which computes the prior.\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m mvn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\models.py:232\u001b[0m, in \u001b[0;36mCovNet.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mcg_tolerance(settings\u001b[38;5;241m.\u001b[39meval_cg_tolerance\u001b[38;5;241m.\u001b[39mvalue()):\n\u001b[0;32m    229\u001b[0m     (\n\u001b[0;32m    230\u001b[0m         predictive_mean,\n\u001b[0;32m    231\u001b[0m         predictive_covar,\n\u001b[1;32m--> 232\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[0;32m    235\u001b[0m predictive_mean \u001b[38;5;241m=\u001b[39m predictive_mean\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtest_shape)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:289\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[1;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[0;32m    285\u001b[0m     test_test_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :]\n\u001b[0;32m    286\u001b[0m     test_train_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train]\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_predictive_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_covar\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexact_predictive_covar(test_test_covar, test_train_covar),\n\u001b[0;32m    291\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:306\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_mean\u001b[1;34m(self, test_mean, test_train_covar)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03mComputes the posterior predictive covariance of a GP\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;124;03m:return: The predictive posterior mean of the test points\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# NOTE TO FUTURE SELF:\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# You **cannot* use addmv here, because test_train_covar may not actually be a non lazy tensor even for an exact\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# GP, and using addmv requires you to to_dense test_train_covar, which is obviously a huge no-no!\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_cache\u001b[49m\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    307\u001b[0m     res \u001b[38;5;241m=\u001b[39m (test_train_covar \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_cache\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:256\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.mean_cache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m train_mean, train_train_covar \u001b[38;5;241m=\u001b[39m mvn\u001b[38;5;241m.\u001b[39mloc, mvn\u001b[38;5;241m.\u001b[39mlazy_covariance_matrix\n\u001b[0;32m    255\u001b[0m train_labels_offset \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels \u001b[38;5;241m-\u001b[39m train_mean)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 256\u001b[0m mean_cache \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_train_covar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msolve(train_labels_offset)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mdetach_test_caches\u001b[38;5;241m.\u001b[39mon():\n\u001b[0;32m    259\u001b[0m     mean_cache \u001b[38;5;241m=\u001b[39m mean_cache\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\added_diag_linear_operator.py:209\u001b[0m, in \u001b[0;36mAddedDiagLinearOperator.evaluate_kernel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 209\u001b[0m     added_diag_linear_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation())\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_linear_op \u001b[38;5;241m+\u001b[39m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_diag_tensor\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:2064\u001b[0m, in \u001b[0;36mLinearOperator.representation_tree\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresentation_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LinearOperatorRepresentationTree:\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2056\u001b[0m \u001b[38;5;124;03m    Returns a\u001b[39;00m\n\u001b[0;32m   2057\u001b[0m \u001b[38;5;124;03m    :obj:`linear_operator.operators.LinearOperatorRepresentationTree` tree\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2062\u001b[0m \u001b[38;5;124;03m    including all subobjects. This is used internally.\u001b[39;00m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLinearOperatorRepresentationTree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\linear_operator_representation_tree.py:15\u001b[0m, in \u001b[0;36mLinearOperatorRepresentationTree.__init__\u001b[1;34m(self, linear_op)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(linear_op\u001b[38;5;241m.\u001b[39m_args, linear_op\u001b[38;5;241m.\u001b[39m_differentiable_kwargs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepresentation\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(arg\u001b[38;5;241m.\u001b[39mrepresentation):  \u001b[38;5;66;03m# Is it a lazy tensor?\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m         representation_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mslice\u001b[39m(counter, counter \u001b[38;5;241m+\u001b[39m representation_size, \u001b[38;5;28;01mNone\u001b[39;00m), arg\u001b[38;5;241m.\u001b[39mrepresentation_tree()))\n\u001b[0;32m     17\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m representation_size\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:397\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.representation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrepresentation()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# Otherwise, we'll evaluate the kernel (or at least its LinearOperator representation) and use its\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# representation\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepresentation()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_grad_enabled):\n\u001b[1;32m---> 25\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\kernels\\kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[0;32m    527\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[1;32m--> 530\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\kernels.py:46\u001b[0m, in \u001b[0;36mDeepSumKernel.forward\u001b[1;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[0;32m     44\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mls1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ls1[:, i, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m     45\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mls2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ls2[:, i, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m---> 46\u001b[0m next_term \u001b[38;5;241m=\u001b[39m \u001b[43mkern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m diag:\n\u001b[0;32m     48\u001b[0m     k \u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m+\u001b[39m to_linear_operator(next_term)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\kernels\\kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[0;32m    527\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[1;32m--> 530\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\kernels.py:120\u001b[0m, in \u001b[0;36mDeepRQKernel.forward\u001b[1;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[0;32m    117\u001b[0m x1_ \u001b[38;5;241m=\u001b[39m x1\u001b[38;5;241m.\u001b[39mmul(ls1)\n\u001b[0;32m    118\u001b[0m x2_ \u001b[38;5;241m=\u001b[39m x2\u001b[38;5;241m.\u001b[39mmul(ls2)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m postprocess_rq(\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquare_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    121\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\kernels\\kernel.py:357\u001b[0m, in \u001b[0;36mKernel.covar_dist\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, square_dist, **params)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     dist_func \u001b[38;5;241m=\u001b[39m sq_dist \u001b[38;5;28;01mif\u001b[39;00m square_dist \u001b[38;5;28;01melse\u001b[39;00m dist\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdist_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1_eq_x2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\kernels\\kernel.py:43\u001b[0m, in \u001b[0;36msq_dist\u001b[1;34m(x1, x2, x1_eq_x2)\u001b[0m\n\u001b[0;32m     41\u001b[0m x1_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m x1, x1_norm, x1_pad], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     42\u001b[0m x2_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x2, x2_pad, x2_norm], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mx1_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x1_eq_x2 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x1\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x2\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m     46\u001b[0m     res\u001b[38;5;241m.\u001b[39mdiagonal(dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4411935125000 bytes."
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "epochs = 1\n",
    "model = Model(X_scaled, y_trq_np, noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "model.fit(epochs=epochs, verbose=True)\n",
    "\n",
    "uncertainties=[]\n",
    "predictions=[]\n",
    "for i, test_sample in enumerate(X_test_scaled[:10]):\n",
    "    if i%50==0:\n",
    "        print(i)\n",
    "    print(i)\n",
    "    indicies = get_closest_samples(X_scaled, test_sample, 1000)\n",
    "    # model = Model(X_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "    # model.fit(epochs=epochs, verbose=False)\n",
    "    # y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    # model = Model(X_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "    # model.fit(epochs=epochs, verbose=False)\n",
    "    # y_pred_2, lcb_2, ucb_2 = model.predict(test_sample, pred_var=True)\n",
    "    # print(y_pred)\n",
    "    # print(y_pred_2)\n",
    "    for i in range(5):\n",
    "\n",
    "        y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "        print(y_pred)\n",
    "    print(ucb-y_pred)\n",
    "    y_pred, v = closer_to_zero(y_pred, y_pred_2)\n",
    "    if v ==1:\n",
    "        uncertainty = ucb-y_pred\n",
    "    else:\n",
    "        uncertainty = ucb_2-y_pred\n",
    "    se = uncertainty/1.96\n",
    "    if se<0.01:\n",
    "        se=0.01\n",
    "    predictions.append(y_pred)\n",
    "    uncertainties.append(se)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "predictions = torch.stack(predictions)\n",
    "uncertainties = torch.stack(uncertainties)\n",
    "with open('predictions/reg_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions, f)\n",
    "with open('predictions/reg_se.pkl', 'wb') as f:\n",
    "    pickle.dump(uncertainties, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.5984]],\n",
       "\n",
       "        [[ 1.5980]],\n",
       "\n",
       "        [[-0.1050]],\n",
       "\n",
       "        [[ 0.4020]],\n",
       "\n",
       "        [[ 5.0188]],\n",
       "\n",
       "        [[-3.3772]],\n",
       "\n",
       "        [[16.3842]],\n",
       "\n",
       "        [[14.6752]],\n",
       "\n",
       "        [[ 9.3880]],\n",
       "\n",
       "        [[10.2127]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(exp_train)\n",
    "X_test_scaled = scaler.transform(exp_test)\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X_test_scaled)\n",
    "\n",
    "# Get centroids and predict clusters\n",
    "centroids = kmeans.cluster_centers_\n",
    "cluster_labels = kmeans.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[6.9089]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0529]], dtype=torch.float64)\n",
      "Prediction: tensor([[-2.4258]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[5.8726]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0134]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.9882]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.6858]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0030]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-07 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[0.2890]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.1645]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0042]], dtype=torch.float64)\n",
      "Prediction: tensor([[-73.8154]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0645]], dtype=torch.float64)\n",
      "Prediction: tensor([[2.0928]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.8903]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0044]], dtype=torch.float64)\n",
      "Prediction: tensor([[1.8151]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[6.5995]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.2484]], dtype=torch.float64)\n",
      "Prediction: tensor([[-19.3530]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4016]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0016]], dtype=torch.float64)\n",
      "Prediction: tensor([[17.3280]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0223]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.3931]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[5.1737]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0225]], dtype=torch.float64)\n",
      "Prediction: tensor([[6.6107]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0333]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0038]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.5539]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.3181]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0277]], dtype=torch.float64)\n",
      "Prediction: tensor([[8.5595]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.6361]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0350]], dtype=torch.float64)\n",
      "Prediction: tensor([[-4.3580]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0197]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0019]], dtype=torch.float64)\n",
      "Prediction: tensor([[14.7915]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.7180]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0029]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.8300]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.1735]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0003]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.4698]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.7968]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0129]], dtype=torch.float64)\n",
      "Prediction: tensor([[-530.4930]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-525.5746]], dtype=torch.float64)\n",
      "Prediction: tensor([[-21.4685]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[7.9628]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.3879]], dtype=torch.float64)\n",
      "Prediction: tensor([[18.2260]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.9203]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0002]], dtype=torch.float64)\n",
      "Prediction: tensor([[8.4333]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[3.1316]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0409]], dtype=torch.float64)\n",
      "Prediction: tensor([[-15.1881]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0091]], dtype=torch.float64)\n",
      "Prediction: tensor([[11.4425]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.7184]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0036]], dtype=torch.float64)\n",
      "Prediction: tensor([[10.8490]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.9607]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0220]], dtype=torch.float64)\n",
      "Prediction: tensor([[4.6128]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0003]], dtype=torch.float64)\n",
      "Prediction: tensor([[14.4682]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.3851]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0049]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.0239]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.1478]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0015]], dtype=torch.float64)\n",
      "Prediction: tensor([[11.7365]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.2759]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0089]], dtype=torch.float64)\n",
      "Prediction: tensor([[2.0065]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.6902]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0009]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.1615]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.4741]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0017]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.9749]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4770]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0161]], dtype=torch.float64)\n",
      "Prediction: tensor([[-1.3807]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.9538]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0079]], dtype=torch.float64)\n",
      "Prediction: tensor([[3.2899]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.5832]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0180]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.1097]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.6496]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0007]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.1680]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.2857]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.1591]], dtype=torch.float64)\n",
      "Prediction: tensor([[-3.6131]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0155]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.9135]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0007]], dtype=torch.float64)\n",
      "Prediction: tensor([[10.2564]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.6481]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0116]], dtype=torch.float64)\n",
      "Prediction: tensor([[-5.9592]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0086]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0021]], dtype=torch.float64)\n",
      "Prediction: tensor([[14.7150]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0585]], dtype=torch.float64)\n",
      "Prediction: tensor([[16.5722]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.6159]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0015]], dtype=torch.float64)\n",
      "Prediction: tensor([[-17.5473]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.9837]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0043]], dtype=torch.float64)\n",
      "Prediction: tensor([[4.3196]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.4831]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0640]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.1776]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0140]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-1.4350e-05]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.0034]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0171]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0003]], dtype=torch.float64)\n",
      "Prediction: tensor([[8.5153]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.3276]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0078]], dtype=torch.float64)\n",
      "Prediction: tensor([[-0.7466]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0006]], dtype=torch.float64)\n",
      "Prediction: tensor([[17.1361]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.3508]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0001]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.0338]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.6270]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0007]], dtype=torch.float64)\n",
      "Prediction: tensor([[0.1646]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0334]], dtype=torch.float64)\n",
      "tensor([[-10.5036]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "errors= []\n",
    "upper=[]\n",
    "predictions=[]\n",
    "for i, test_sample in enumerate(X_test_scaled):\n",
    "    indicies = get_closest_samples(X_scaled, test_sample, 10000)\n",
    "    model = Model(X_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-2)\n",
    "    model.fit(epochs=2, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    predictions.append(y_pred.to('cpu').reshape(-1))\n",
    "    upper.append(ucb.to('cpu'))\n",
    "    print(f\"Prediction: {y_pred}\")\n",
    "    print(f\"Uncertainty: {ucb-y_pred}\")\n",
    "    print(f\"real_value_error: {y_pred-torch.tensor(exp_y_test[i])}\")\n",
    "    errors.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "\n",
    "mean_tensor = torch.stack(errors).mean(dim=0)\n",
    "\n",
    "print(mean_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[6.9696]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0077]], dtype=torch.float64)\n",
      "Prediction: tensor([[-2.3325]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.2905]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.1067]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.9848]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0070]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0004]], dtype=torch.float64)\n",
      "Prediction: tensor([[0.2856]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.5156]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0008]], dtype=torch.float64)\n",
      "Prediction: tensor([[-73.8721]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3973]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0078]], dtype=torch.float64)\n",
      "Prediction: tensor([[2.0928]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.3880]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0044]], dtype=torch.float64)\n",
      "Prediction: tensor([[1.5430]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[3.6367]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0236]], dtype=torch.float64)\n",
      "Prediction: tensor([[-19.3419]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0849]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0094]], dtype=torch.float64)\n",
      "Prediction: tensor([[17.3894]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0744]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0391]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.4348]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.5426]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0192]], dtype=torch.float64)\n",
      "Prediction: tensor([[6.6087]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.0069]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0018]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.6187]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.1982]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0925]], dtype=torch.float64)\n",
      "Prediction: tensor([[8.5184]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4550]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0060]], dtype=torch.float64)\n",
      "Prediction: tensor([[-4.3496]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0131]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0066]], dtype=torch.float64)\n",
      "Prediction: tensor([[14.7904]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.6242]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0017]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.8193]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[3.0940]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0110]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.4592]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.8417]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0022]], dtype=torch.float64)\n",
      "Prediction: tensor([[-4.9232]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0048]], dtype=torch.float64)\n",
      "Prediction: tensor([[-21.6866]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[4.2208]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.1699]], dtype=torch.float64)\n",
      "Prediction: tensor([[18.2240]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4929]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0018]], dtype=torch.float64)\n",
      "Prediction: tensor([[8.3731]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[3.9354]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0193]], dtype=torch.float64)\n",
      "Prediction: tensor([[-15.1799]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5729]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0010]], dtype=torch.float64)\n",
      "Prediction: tensor([[11.4638]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.8919]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0248]], dtype=torch.float64)\n",
      "Prediction: tensor([[10.8579]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.0157]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0132]], dtype=torch.float64)\n",
      "Prediction: tensor([[4.6131]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0197]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-3.9563e-05]], dtype=torch.float64)\n",
      "Prediction: tensor([[14.7174]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1481]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.2443]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.0228]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1291]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0004]], dtype=torch.float64)\n",
      "Prediction: tensor([[11.7405]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5012]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0048]], dtype=torch.float64)\n",
      "Prediction: tensor([[1.9952]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.7849]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0103]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.1583]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.8844]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0015]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.9532]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2501]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0378]], dtype=torch.float64)\n",
      "Prediction: tensor([[-1.3776]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.9389]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0048]], dtype=torch.float64)\n",
      "Prediction: tensor([[3.2790]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.3952]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0071]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.1115]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.4834]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0011]], dtype=torch.float64)\n",
      "Prediction: tensor([[-6.9812]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.5881]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0277]], dtype=torch.float64)\n",
      "Prediction: tensor([[-3.6290]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0100]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0004]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.9171]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0042]], dtype=torch.float64)\n",
      "Prediction: tensor([[10.2666]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.2335]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0014]], dtype=torch.float64)\n",
      "Prediction: tensor([[-5.9595]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0134]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0019]], dtype=torch.float64)\n",
      "Prediction: tensor([[14.7743]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.1204]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0008]], dtype=torch.float64)\n",
      "Prediction: tensor([[16.5874]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.0409]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0167]], dtype=torch.float64)\n",
      "Prediction: tensor([[-17.5448]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.2631]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0069]], dtype=torch.float64)\n",
      "Prediction: tensor([[4.3874]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.6135]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0038]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.1785]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0010]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.0035]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0125]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0002]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.9220]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0715]], dtype=torch.float64)\n",
      "real_value_error: tensor([[1.3989]], dtype=torch.float64)\n",
      "Prediction: tensor([[-0.7471]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0139]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0001]], dtype=torch.float64)\n",
      "Prediction: tensor([[17.1394]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.2256]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0035]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.0329]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.7855]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0015]], dtype=torch.float64)\n",
      "Prediction: tensor([[0.1969]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0011]], dtype=torch.float64)\n",
      "tensor([[0.0412]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "errors= []\n",
    "upper=[]\n",
    "predictions=[]\n",
    "for i, test_sample in enumerate(X_test_scaled):\n",
    "    indicies = get_closest_samples(X_scaled, test_sample, 5000)\n",
    "    model = Model(X_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-2)\n",
    "    model.fit(epochs=2, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    predictions.append(y_pred.to('cpu').reshape(-1))\n",
    "    upper.append(ucb.to('cpu'))\n",
    "    print(f\"Prediction: {y_pred}\")\n",
    "    print(f\"Uncertainty: {ucb-y_pred}\")\n",
    "    print(f\"real_value_error: {y_pred-torch.tensor(exp_y_test[i])}\")\n",
    "    errors.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "    \n",
    "\n",
    "mean_tensor = torch.stack(errors).mean(dim=0)\n",
    "\n",
    "print(mean_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[6.9618]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0178]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-7.1135e-05]], dtype=torch.float64)\n",
      "1\n",
      "Prediction: tensor([[-2.3709]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.2972]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0683]], dtype=torch.float64)\n",
      "2\n",
      "Prediction: tensor([[9.9786]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5514]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0066]], dtype=torch.float64)\n",
      "3\n",
      "Prediction: tensor([[0.2732]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4098]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0116]], dtype=torch.float64)\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[-73.8809]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0010]], dtype=torch.float64)\n",
      "5\n",
      "Prediction: tensor([[2.0951]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.8294]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0067]], dtype=torch.float64)\n",
      "6\n",
      "Prediction: tensor([[1.5952]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.1594]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0286]], dtype=torch.float64)\n",
      "7\n",
      "Prediction: tensor([[-19.3549]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0660]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0035]], dtype=torch.float64)\n",
      "8\n",
      "Prediction: tensor([[17.3434]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.6119]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0069]], dtype=torch.float64)\n",
      "9\n",
      "Prediction: tensor([[7.4266]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4590]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0110]], dtype=torch.float64)\n",
      "10\n",
      "Prediction: tensor([[6.6237]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.6545]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0168]], dtype=torch.float64)\n",
      "11\n",
      "Prediction: tensor([[9.5435]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5085]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0173]], dtype=torch.float64)\n",
      "12\n",
      "Prediction: tensor([[8.5486]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3714]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0241]], dtype=torch.float64)\n",
      "13\n",
      "Prediction: tensor([[-4.3564]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0138]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0002]], dtype=torch.float64)\n",
      "14\n",
      "Prediction: tensor([[14.7888]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4152]], dtype=torch.float64)\n",
      "real_value_error: tensor([[7.8361e-05]], dtype=torch.float64)\n",
      "15\n",
      "Prediction: tensor([[9.8147]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.0203]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0156]], dtype=torch.float64)\n",
      "16\n",
      "Prediction: tensor([[9.4616]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.7362]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0046]], dtype=torch.float64)\n",
      "17\n",
      "Prediction: tensor([[-4.9169]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0015]], dtype=torch.float64)\n",
      "18\n",
      "Prediction: tensor([[-21.5667]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.8971]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.2898]], dtype=torch.float64)\n",
      "19\n",
      "Prediction: tensor([[18.2252]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3733]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0006]], dtype=torch.float64)\n",
      "20\n",
      "Prediction: tensor([[8.3831]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.4019]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0092]], dtype=torch.float64)\n",
      "21\n",
      "Prediction: tensor([[-15.1821]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0455]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0031]], dtype=torch.float64)\n",
      "22\n",
      "Prediction: tensor([[11.4418]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5534]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0029]], dtype=torch.float64)\n",
      "23\n",
      "Prediction: tensor([[10.8327]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.8017]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0383]], dtype=torch.float64)\n",
      "24\n",
      "Prediction: tensor([[4.6139]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0138]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0008]], dtype=torch.float64)\n",
      "25\n",
      "Prediction: tensor([[15.1226]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3221]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.6494]], dtype=torch.float64)\n",
      "26\n",
      "Prediction: tensor([[7.0394]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0170]], dtype=torch.float64)\n",
      "27\n",
      "Prediction: tensor([[11.7520]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1273]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0066]], dtype=torch.float64)\n",
      "28\n",
      "Prediction: tensor([[2.1218]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1553]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.1162]], dtype=torch.float64)\n",
      "29\n",
      "Prediction: tensor([[7.1580]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3220]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0017]], dtype=torch.float64)\n",
      "30\n",
      "Prediction: tensor([[7.9761]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0505]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0149]], dtype=torch.float64)\n",
      "31\n",
      "Prediction: tensor([[-1.3922]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2728]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0193]], dtype=torch.float64)\n",
      "32\n",
      "Prediction: tensor([[3.2745]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.6581]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0026]], dtype=torch.float64)\n",
      "33\n",
      "Prediction: tensor([[9.0949]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.9615]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0155]], dtype=torch.float64)\n",
      "34\n",
      "Prediction: tensor([[-7.0140]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5530]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0051]], dtype=torch.float64)\n",
      "35\n",
      "Prediction: tensor([[-3.6276]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0087]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0010]], dtype=torch.float64)\n",
      "36\n",
      "Prediction: tensor([[-7.9111]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0131]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0018]], dtype=torch.float64)\n",
      "37\n",
      "Prediction: tensor([[10.2542]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3189]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0139]], dtype=torch.float64)\n",
      "38\n",
      "Prediction: tensor([[-5.9613]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0132]], dtype=torch.float64)\n",
      "real_value_error: tensor([[7.6709e-05]], dtype=torch.float64)\n",
      "39\n",
      "Prediction: tensor([[14.8175]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3138]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0440]], dtype=torch.float64)\n",
      "40\n",
      "Prediction: tensor([[16.5744]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5130]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0037]], dtype=torch.float64)\n",
      "41\n",
      "Prediction: tensor([[-17.5380]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5010]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0136]], dtype=torch.float64)\n",
      "42\n",
      "Prediction: tensor([[4.3720]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.0101]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0116]], dtype=torch.float64)\n",
      "43\n",
      "Prediction: tensor([[-7.1982]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0125]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0206]], dtype=torch.float64)\n",
      "44\n",
      "Prediction: tensor([[-7.0023]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0014]], dtype=torch.float64)\n",
      "45\n",
      "Prediction: tensor([[8.5203]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3197]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0028]], dtype=torch.float64)\n",
      "46\n",
      "Prediction: tensor([[-0.7723]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0120]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0251]], dtype=torch.float64)\n",
      "47\n",
      "Prediction: tensor([[17.1340]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2355]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0019]], dtype=torch.float64)\n",
      "48\n",
      "Prediction: tensor([[-7.0359]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4953]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0014]], dtype=torch.float64)\n",
      "49\n",
      "Prediction: tensor([[0.1953]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0195]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0027]], dtype=torch.float64)\n",
      "50\n",
      "Prediction: tensor([[11.4093]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4396]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0561]], dtype=torch.float64)\n",
      "51\n",
      "Prediction: tensor([[-6.9745]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0132]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0149]], dtype=torch.float64)\n",
      "52\n",
      "Prediction: tensor([[5.4249]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.0600]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.1771]], dtype=torch.float64)\n",
      "53\n",
      "Prediction: tensor([[7.7321]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2445]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0031]], dtype=torch.float64)\n",
      "54\n",
      "Prediction: tensor([[-13.6065]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.8094]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0271]], dtype=torch.float64)\n",
      "55\n",
      "Prediction: tensor([[-20.1310]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4511]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.1061]], dtype=torch.float64)\n",
      "56\n",
      "Prediction: tensor([[2.6764]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.2328]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0057]], dtype=torch.float64)\n",
      "57\n",
      "Prediction: tensor([[8.1515]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.9553]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0501]], dtype=torch.float64)\n",
      "58\n",
      "Prediction: tensor([[-18.8752]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0035]], dtype=torch.float64)\n",
      "59\n",
      "Prediction: tensor([[13.0106]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0231]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-3.1384e-05]], dtype=torch.float64)\n",
      "60\n",
      "Prediction: tensor([[-12.4113]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0165]], dtype=torch.float64)\n",
      "61\n",
      "Prediction: tensor([[-6.2482]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0092]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0091]], dtype=torch.float64)\n",
      "62\n",
      "Prediction: tensor([[-3.9877]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.5618]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0468]], dtype=torch.float64)\n",
      "63\n",
      "Prediction: tensor([[7.6901]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.9147]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0054]], dtype=torch.float64)\n",
      "64\n",
      "Prediction: tensor([[24.2277]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0164]], dtype=torch.float64)\n",
      "65\n",
      "Prediction: tensor([[2.3071]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.3511]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0695]], dtype=torch.float64)\n",
      "66\n",
      "Prediction: tensor([[-5.8838]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0134]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0018]], dtype=torch.float64)\n",
      "67\n",
      "Prediction: tensor([[-18.6554]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1100]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0111]], dtype=torch.float64)\n",
      "68\n",
      "Prediction: tensor([[8.3797]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3364]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0007]], dtype=torch.float64)\n",
      "69\n",
      "Prediction: tensor([[3.4197]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3241]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0024]], dtype=torch.float64)\n",
      "70\n",
      "Prediction: tensor([[1.2793]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.1700]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0546]], dtype=torch.float64)\n",
      "71\n",
      "Prediction: tensor([[2.1076]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3979]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0022]], dtype=torch.float64)\n",
      "72\n",
      "Prediction: tensor([[-9.9888]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4794]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0009]], dtype=torch.float64)\n",
      "73\n",
      "Prediction: tensor([[-11.6501]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0034]], dtype=torch.float64)\n",
      "74\n",
      "Prediction: tensor([[-2.8320]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.9872]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0114]], dtype=torch.float64)\n",
      "75\n",
      "Prediction: tensor([[-12.2308]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.4657]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0077]], dtype=torch.float64)\n",
      "76\n",
      "Prediction: tensor([[12.6400]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4326]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0001]], dtype=torch.float64)\n",
      "77\n",
      "Prediction: tensor([[-2.2103]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0397]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0022]], dtype=torch.float64)\n",
      "78\n",
      "Prediction: tensor([[8.4051]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.6973]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0149]], dtype=torch.float64)\n",
      "79\n",
      "Prediction: tensor([[5.1649]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1184]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-1.0214e-05]], dtype=torch.float64)\n",
      "80\n",
      "Prediction: tensor([[2.9907]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.6553]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0077]], dtype=torch.float64)\n",
      "81\n",
      "Prediction: tensor([[13.2190]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.7558]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0111]], dtype=torch.float64)\n",
      "82\n",
      "Prediction: tensor([[-18.0180]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0880]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0030]], dtype=torch.float64)\n",
      "83\n",
      "Prediction: tensor([[-14.6193]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.7726]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0159]], dtype=torch.float64)\n",
      "84\n",
      "Prediction: tensor([[-2.6646]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1821]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0005]], dtype=torch.float64)\n",
      "85\n",
      "Prediction: tensor([[-5.3548]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3490]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0061]], dtype=torch.float64)\n",
      "86\n",
      "Prediction: tensor([[-16.0152]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.6379]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0003]], dtype=torch.float64)\n",
      "87\n",
      "Prediction: tensor([[2.8635]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0129]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0006]], dtype=torch.float64)\n",
      "88\n",
      "Prediction: tensor([[8.8934]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.6501]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0274]], dtype=torch.float64)\n",
      "89\n",
      "Prediction: tensor([[-7.0312]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1402]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0026]], dtype=torch.float64)\n",
      "90\n",
      "Prediction: tensor([[0.5417]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.9232]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0251]], dtype=torch.float64)\n",
      "91\n",
      "Prediction: tensor([[11.7779]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.8071]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0816]], dtype=torch.float64)\n",
      "92\n",
      "Prediction: tensor([[2.1403]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.8564]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0114]], dtype=torch.float64)\n",
      "93\n",
      "Prediction: tensor([[13.4353]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4083]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0078]], dtype=torch.float64)\n",
      "94\n",
      "Prediction: tensor([[-5.1925]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0126]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0017]], dtype=torch.float64)\n",
      "95\n",
      "Prediction: tensor([[3.2904]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.2011]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0444]], dtype=torch.float64)\n",
      "96\n",
      "Prediction: tensor([[-2.4214]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0018]], dtype=torch.float64)\n",
      "97\n",
      "Prediction: tensor([[4.2972]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0355]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0025]], dtype=torch.float64)\n",
      "98\n",
      "Prediction: tensor([[-18.7076]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0013]], dtype=torch.float64)\n",
      "99\n",
      "Prediction: tensor([[-8.1342]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.4221]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.3713]], dtype=torch.float64)\n",
      "tensor([[0.0069]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "epochs = 8\n",
    "errors= []\n",
    "\n",
    "upper=[]\n",
    "predictions=[]\n",
    "for i, test_sample in enumerate(X_test_scaled):\n",
    "    indicies = get_closest_samples(X_scaled, test_sample, 1000)\n",
    "    model = Model(X_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "    print(i)\n",
    "        \n",
    "    model.fit(epochs=8, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    errors.append(y_pred-torch.tensor(exp_y_test[i]))   \n",
    "\n",
    "        # predictions.append(y_pred.to('cpu').reshape(-1))\n",
    "        # upper.append(ucb.to('cpu'))\n",
    "    print(f\"Prediction: {y_pred}\")\n",
    "    print(f\"Uncertainty: {ucb-y_pred}\")\n",
    "    print(f\"real_value_error: {y_pred-torch.tensor(exp_y_test[i])}\")\n",
    "        \n",
    "\n",
    "mean_tensor = torch.stack(errors).mean(dim=0)\n",
    "print(mean_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "tensor([[-0.4260]], dtype=torch.float64)\n",
      "tensor([[0.8460]], dtype=torch.float64)\n",
      "tensor([[0.8402]], dtype=torch.float64)\n",
      "tensor([[1.3067]], dtype=torch.float64)\n",
      "tensor([[0.8245]], dtype=torch.float64)\n",
      "tensor([[0.4835]], dtype=torch.float64)\n",
      "tensor([[0.0120]], dtype=torch.float64)\n",
      "tensor([[-0.0855]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "epochs = 8\n",
    "errors_1= []\n",
    "errors_2= []\n",
    "errors_3= []\n",
    "errors_4= []\n",
    "errors_5= []\n",
    "errors_6= []\n",
    "errors_7= []\n",
    "errors_8= []\n",
    "upper=[]\n",
    "predictions=[]\n",
    "for i, test_sample in enumerate(X_test_scaled):\n",
    "    indicies = get_closest_samples(X_scaled, test_sample, 1000)\n",
    "    model = Model(X_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "    print(i)\n",
    "        \n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    errors_1.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    errors_2.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    errors_3.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    errors_4.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    errors_5.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    errors_6.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    errors_7.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    errors_8.append(y_pred-torch.tensor(exp_y_test[i]))        \n",
    "\n",
    "        # predictions.append(y_pred.to('cpu').reshape(-1))\n",
    "        # upper.append(ucb.to('cpu'))\n",
    "    print(f\"Prediction: {y_pred}\")\n",
    "    print(f\"Uncertainty: {ucb-y_pred}\")\n",
    "    print(f\"real_value_error: {y_pred-torch.tensor(exp_y_test[i])}\")\n",
    "        \n",
    "\n",
    "mean_tensor = torch.stack(errors_1).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_2).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_3).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_4).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_5).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_6).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_7).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_8).mean(dim=0)\n",
    "\n",
    "print(mean_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0010]], dtype=torch.float64),\n",
       " tensor([[-0.0392]], dtype=torch.float64),\n",
       " tensor([[-0.0010]], dtype=torch.float64),\n",
       " tensor([[-0.0016]], dtype=torch.float64),\n",
       " tensor([[-0.3058]], dtype=torch.float64),\n",
       " tensor([[-0.0137]], dtype=torch.float64),\n",
       " tensor([[0.0025]], dtype=torch.float64),\n",
       " tensor([[-0.0441]], dtype=torch.float64),\n",
       " tensor([[0.0984]], dtype=torch.float64),\n",
       " tensor([[-0.0102]], dtype=torch.float64),\n",
       " tensor([[0.0026]], dtype=torch.float64),\n",
       " tensor([[0.2095]], dtype=torch.float64),\n",
       " tensor([[-0.0355]], dtype=torch.float64),\n",
       " tensor([[0.0005]], dtype=torch.float64),\n",
       " tensor([[0.0061]], dtype=torch.float64),\n",
       " tensor([[0.0048]], dtype=torch.float64),\n",
       " tensor([[0.0840]], dtype=torch.float64),\n",
       " tensor([[-0.0007]], dtype=torch.float64),\n",
       " tensor([[-3.7090e-05]], dtype=torch.float64),\n",
       " tensor([[-0.0234]], dtype=torch.float64),\n",
       " tensor([[-0.1021]], dtype=torch.float64),\n",
       " tensor([[-0.1298]], dtype=torch.float64),\n",
       " tensor([[0.0020]], dtype=torch.float64),\n",
       " tensor([[-0.0003]], dtype=torch.float64),\n",
       " tensor([[0.0012]], dtype=torch.float64),\n",
       " tensor([[0.0075]], dtype=torch.float64),\n",
       " tensor([[0.0008]], dtype=torch.float64),\n",
       " tensor([[-0.0026]], dtype=torch.float64),\n",
       " tensor([[0.0011]], dtype=torch.float64),\n",
       " tensor([[0.0053]], dtype=torch.float64),\n",
       " tensor([[-0.0161]], dtype=torch.float64),\n",
       " tensor([[-0.0002]], dtype=torch.float64),\n",
       " tensor([[0.0386]], dtype=torch.float64),\n",
       " tensor([[-0.0012]], dtype=torch.float64),\n",
       " tensor([[0.0066]], dtype=torch.float64),\n",
       " tensor([[-0.0003]], dtype=torch.float64),\n",
       " tensor([[0.0016]], dtype=torch.float64),\n",
       " tensor([[-0.0033]], dtype=torch.float64),\n",
       " tensor([[0.0005]], dtype=torch.float64),\n",
       " tensor([[0.0663]], dtype=torch.float64),\n",
       " tensor([[0.0254]], dtype=torch.float64),\n",
       " tensor([[0.0105]], dtype=torch.float64),\n",
       " tensor([[-0.0409]], dtype=torch.float64),\n",
       " tensor([[-0.0002]], dtype=torch.float64),\n",
       " tensor([[0.0080]], dtype=torch.float64),\n",
       " tensor([[0.0018]], dtype=torch.float64),\n",
       " tensor([[-0.0151]], dtype=torch.float64),\n",
       " tensor([[-0.1287]], dtype=torch.float64),\n",
       " tensor([[0.0182]], dtype=torch.float64),\n",
       " tensor([[-0.0004]], dtype=torch.float64),\n",
       " tensor([[-0.0022]], dtype=torch.float64),\n",
       " tensor([[-0.0006]], dtype=torch.float64),\n",
       " tensor([[0.0016]], dtype=torch.float64),\n",
       " tensor([[-0.0018]], dtype=torch.float64),\n",
       " tensor([[-0.2141]], dtype=torch.float64),\n",
       " tensor([[-0.0129]], dtype=torch.float64),\n",
       " tensor([[-0.0335]], dtype=torch.float64),\n",
       " tensor([[-0.0856]], dtype=torch.float64),\n",
       " tensor([[-0.0002]], dtype=torch.float64),\n",
       " tensor([[0.0118]], dtype=torch.float64),\n",
       " tensor([[0.0270]], dtype=torch.float64),\n",
       " tensor([[0.0019]], dtype=torch.float64),\n",
       " tensor([[0.0135]], dtype=torch.float64),\n",
       " tensor([[-0.0015]], dtype=torch.float64),\n",
       " tensor([[-0.0063]], dtype=torch.float64),\n",
       " tensor([[-0.0017]], dtype=torch.float64),\n",
       " tensor([[2.6407e-05]], dtype=torch.float64),\n",
       " tensor([[0.0028]], dtype=torch.float64),\n",
       " tensor([[0.0056]], dtype=torch.float64),\n",
       " tensor([[-0.0006]], dtype=torch.float64),\n",
       " tensor([[-0.0060]], dtype=torch.float64),\n",
       " tensor([[-0.0367]], dtype=torch.float64),\n",
       " tensor([[0.0374]], dtype=torch.float64),\n",
       " tensor([[-0.1539]], dtype=torch.float64),\n",
       " tensor([[-0.0044]], dtype=torch.float64),\n",
       " tensor([[-0.0163]], dtype=torch.float64),\n",
       " tensor([[0.0037]], dtype=torch.float64),\n",
       " tensor([[0.0066]], dtype=torch.float64),\n",
       " tensor([[-0.0062]], dtype=torch.float64),\n",
       " tensor([[-0.0223]], dtype=torch.float64),\n",
       " tensor([[-0.0222]], dtype=torch.float64),\n",
       " tensor([[0.0029]], dtype=torch.float64),\n",
       " tensor([[0.0041]], dtype=torch.float64),\n",
       " tensor([[-0.0153]], dtype=torch.float64),\n",
       " tensor([[0.0005]], dtype=torch.float64),\n",
       " tensor([[-0.0032]], dtype=torch.float64),\n",
       " tensor([[-0.0066]], dtype=torch.float64),\n",
       " tensor([[-0.0026]], dtype=torch.float64),\n",
       " tensor([[-0.0041]], dtype=torch.float64),\n",
       " tensor([[-0.0092]], dtype=torch.float64),\n",
       " tensor([[0.0026]], dtype=torch.float64),\n",
       " tensor([[-0.0186]], dtype=torch.float64),\n",
       " tensor([[0.0225]], dtype=torch.float64),\n",
       " tensor([[-0.0140]], dtype=torch.float64),\n",
       " tensor([[-0.0009]], dtype=torch.float64),\n",
       " tensor([[-0.0094]], dtype=torch.float64),\n",
       " tensor([[0.0248]], dtype=torch.float64),\n",
       " tensor([[0.0023]], dtype=torch.float64),\n",
       " tensor([[0.0046]], dtype=torch.float64),\n",
       " tensor([[-0.0037]], dtype=torch.float64),\n",
       " tensor([[0.0004]], dtype=torch.float64),\n",
       " tensor([[0.0030]], dtype=torch.float64),\n",
       " tensor([[-0.0019]], dtype=torch.float64),\n",
       " tensor([[0.0001]], dtype=torch.float64),\n",
       " tensor([[0.0187]], dtype=torch.float64),\n",
       " tensor([[0.0012]], dtype=torch.float64),\n",
       " tensor([[0.0036]], dtype=torch.float64),\n",
       " tensor([[0.0174]], dtype=torch.float64),\n",
       " tensor([[-0.0100]], dtype=torch.float64),\n",
       " tensor([[-0.0026]], dtype=torch.float64),\n",
       " tensor([[-0.0615]], dtype=torch.float64),\n",
       " tensor([[-0.2235]], dtype=torch.float64),\n",
       " tensor([[-0.0186]], dtype=torch.float64),\n",
       " tensor([[0.0020]], dtype=torch.float64),\n",
       " tensor([[-0.1776]], dtype=torch.float64),\n",
       " tensor([[0.0056]], dtype=torch.float64),\n",
       " tensor([[0.0036]], dtype=torch.float64),\n",
       " tensor([[-0.0046]], dtype=torch.float64),\n",
       " tensor([[-0.1101]], dtype=torch.float64),\n",
       " tensor([[-0.0477]], dtype=torch.float64),\n",
       " tensor([[0.1149]], dtype=torch.float64),\n",
       " tensor([[-0.0157]], dtype=torch.float64),\n",
       " tensor([[-0.0063]], dtype=torch.float64),\n",
       " tensor([[0.0013]], dtype=torch.float64),\n",
       " tensor([[0.0029]], dtype=torch.float64),\n",
       " tensor([[0.0075]], dtype=torch.float64),\n",
       " tensor([[-0.2298]], dtype=torch.float64),\n",
       " tensor([[0.0029]], dtype=torch.float64),\n",
       " tensor([[-0.6398]], dtype=torch.float64),\n",
       " tensor([[0.0005]], dtype=torch.float64),\n",
       " tensor([[-0.0005]], dtype=torch.float64),\n",
       " tensor([[-0.0011]], dtype=torch.float64),\n",
       " tensor([[0.0050]], dtype=torch.float64),\n",
       " tensor([[-0.0128]], dtype=torch.float64),\n",
       " tensor([[0.0149]], dtype=torch.float64),\n",
       " tensor([[0.0017]], dtype=torch.float64),\n",
       " tensor([[-8.5486e-05]], dtype=torch.float64),\n",
       " tensor([[-0.0288]], dtype=torch.float64),\n",
       " tensor([[0.1547]], dtype=torch.float64),\n",
       " tensor([[0.0014]], dtype=torch.float64),\n",
       " tensor([[0.0035]], dtype=torch.float64),\n",
       " tensor([[-0.1649]], dtype=torch.float64),\n",
       " tensor([[-0.0228]], dtype=torch.float64),\n",
       " tensor([[0.0015]], dtype=torch.float64),\n",
       " tensor([[0.0813]], dtype=torch.float64),\n",
       " tensor([[0.0036]], dtype=torch.float64),\n",
       " tensor([[-0.0094]], dtype=torch.float64),\n",
       " tensor([[0.0048]], dtype=torch.float64),\n",
       " tensor([[0.0082]], dtype=torch.float64),\n",
       " tensor([[-0.0170]], dtype=torch.float64),\n",
       " tensor([[-0.0024]], dtype=torch.float64),\n",
       " tensor([[0.0001]], dtype=torch.float64),\n",
       " tensor([[-0.0011]], dtype=torch.float64),\n",
       " tensor([[0.0017]], dtype=torch.float64),\n",
       " tensor([[0.0033]], dtype=torch.float64),\n",
       " tensor([[6.9728e-05]], dtype=torch.float64),\n",
       " tensor([[0.0133]], dtype=torch.float64),\n",
       " tensor([[-0.0193]], dtype=torch.float64),\n",
       " tensor([[0.0016]], dtype=torch.float64),\n",
       " tensor([[0.0011]], dtype=torch.float64),\n",
       " tensor([[-0.0340]], dtype=torch.float64),\n",
       " tensor([[-0.0205]], dtype=torch.float64),\n",
       " tensor([[0.0021]], dtype=torch.float64),\n",
       " tensor([[-0.0027]], dtype=torch.float64),\n",
       " tensor([[0.0485]], dtype=torch.float64),\n",
       " tensor([[-0.0005]], dtype=torch.float64),\n",
       " tensor([[-0.0183]], dtype=torch.float64),\n",
       " tensor([[0.0114]], dtype=torch.float64),\n",
       " tensor([[-0.0030]], dtype=torch.float64),\n",
       " tensor([[-0.0144]], dtype=torch.float64),\n",
       " tensor([[0.0022]], dtype=torch.float64),\n",
       " tensor([[0.0032]], dtype=torch.float64),\n",
       " tensor([[0.0074]], dtype=torch.float64),\n",
       " tensor([[0.0052]], dtype=torch.float64),\n",
       " tensor([[-0.0444]], dtype=torch.float64),\n",
       " tensor([[-0.0418]], dtype=torch.float64),\n",
       " tensor([[0.0180]], dtype=torch.float64),\n",
       " tensor([[0.0013]], dtype=torch.float64),\n",
       " tensor([[-0.0067]], dtype=torch.float64),\n",
       " tensor([[-0.0008]], dtype=torch.float64),\n",
       " tensor([[-0.0076]], dtype=torch.float64),\n",
       " tensor([[0.0035]], dtype=torch.float64),\n",
       " tensor([[0.0057]], dtype=torch.float64),\n",
       " tensor([[-0.0005]], dtype=torch.float64),\n",
       " tensor([[-0.0001]], dtype=torch.float64),\n",
       " tensor([[-0.0223]], dtype=torch.float64),\n",
       " tensor([[-0.0088]], dtype=torch.float64),\n",
       " tensor([[-0.0013]], dtype=torch.float64),\n",
       " tensor([[-0.0178]], dtype=torch.float64),\n",
       " tensor([[-0.0249]], dtype=torch.float64),\n",
       " tensor([[0.0205]], dtype=torch.float64),\n",
       " tensor([[0.0035]], dtype=torch.float64),\n",
       " tensor([[-0.0009]], dtype=torch.float64),\n",
       " tensor([[-0.0108]], dtype=torch.float64),\n",
       " tensor([[0.0092]], dtype=torch.float64),\n",
       " tensor([[0.0071]], dtype=torch.float64),\n",
       " tensor([[-0.0077]], dtype=torch.float64),\n",
       " tensor([[0.0074]], dtype=torch.float64),\n",
       " tensor([[-0.0188]], dtype=torch.float64),\n",
       " tensor([[0.0067]], dtype=torch.float64),\n",
       " tensor([[-0.0018]], dtype=torch.float64),\n",
       " tensor([[0.0461]], dtype=torch.float64),\n",
       " tensor([[0.0019]], dtype=torch.float64),\n",
       " tensor([[0.0102]], dtype=torch.float64),\n",
       " tensor([[-0.0025]], dtype=torch.float64),\n",
       " tensor([[0.0067]], dtype=torch.float64),\n",
       " tensor([[-0.0164]], dtype=torch.float64),\n",
       " tensor([[-0.0159]], dtype=torch.float64),\n",
       " tensor([[0.0003]], dtype=torch.float64),\n",
       " tensor([[0.0040]], dtype=torch.float64),\n",
       " tensor([[0.0324]], dtype=torch.float64),\n",
       " tensor([[0.0096]], dtype=torch.float64),\n",
       " tensor([[0.0058]], dtype=torch.float64),\n",
       " tensor([[-0.0125]], dtype=torch.float64),\n",
       " tensor([[-0.0009]], dtype=torch.float64),\n",
       " tensor([[-0.0459]], dtype=torch.float64),\n",
       " tensor([[-0.2103]], dtype=torch.float64),\n",
       " tensor([[0.0196]], dtype=torch.float64),\n",
       " tensor([[0.0173]], dtype=torch.float64),\n",
       " tensor([[-0.1154]], dtype=torch.float64),\n",
       " tensor([[0.0046]], dtype=torch.float64),\n",
       " tensor([[-0.0028]], dtype=torch.float64),\n",
       " tensor([[0.0106]], dtype=torch.float64),\n",
       " tensor([[-0.0058]], dtype=torch.float64),\n",
       " tensor([[-0.0064]], dtype=torch.float64),\n",
       " tensor([[0.0104]], dtype=torch.float64),\n",
       " tensor([[0.0290]], dtype=torch.float64),\n",
       " tensor([[0.0063]], dtype=torch.float64),\n",
       " tensor([[-0.0038]], dtype=torch.float64),\n",
       " tensor([[0.1896]], dtype=torch.float64),\n",
       " tensor([[0.0166]], dtype=torch.float64),\n",
       " tensor([[0.0006]], dtype=torch.float64),\n",
       " tensor([[-0.0100]], dtype=torch.float64),\n",
       " tensor([[0.0245]], dtype=torch.float64),\n",
       " tensor([[0.0156]], dtype=torch.float64),\n",
       " tensor([[0.0012]], dtype=torch.float64),\n",
       " tensor([[0.0730]], dtype=torch.float64),\n",
       " tensor([[0.0077]], dtype=torch.float64),\n",
       " tensor([[0.0092]], dtype=torch.float64),\n",
       " tensor([[-0.0344]], dtype=torch.float64),\n",
       " tensor([[-0.0013]], dtype=torch.float64),\n",
       " tensor([[0.0009]], dtype=torch.float64),\n",
       " tensor([[-0.0046]], dtype=torch.float64),\n",
       " tensor([[-0.0015]], dtype=torch.float64),\n",
       " tensor([[0.0206]], dtype=torch.float64),\n",
       " tensor([[-0.0117]], dtype=torch.float64),\n",
       " tensor([[0.0142]], dtype=torch.float64),\n",
       " tensor([[-0.0007]], dtype=torch.float64),\n",
       " tensor([[-0.0069]], dtype=torch.float64),\n",
       " tensor([[0.0413]], dtype=torch.float64),\n",
       " tensor([[0.0002]], dtype=torch.float64),\n",
       " tensor([[0.0228]], dtype=torch.float64),\n",
       " tensor([[-0.0007]], dtype=torch.float64),\n",
       " tensor([[0.0008]], dtype=torch.float64),\n",
       " tensor([[-0.0004]], dtype=torch.float64),\n",
       " tensor([[0.0229]], dtype=torch.float64),\n",
       " tensor([[0.0119]], dtype=torch.float64),\n",
       " tensor([[-2.1640]], dtype=torch.float64),\n",
       " tensor([[0.0142]], dtype=torch.float64),\n",
       " tensor([[-0.0011]], dtype=torch.float64),\n",
       " tensor([[0.0123]], dtype=torch.float64),\n",
       " tensor([[0.0037]], dtype=torch.float64),\n",
       " tensor([[0.0009]], dtype=torch.float64),\n",
       " tensor([[-0.0065]], dtype=torch.float64),\n",
       " tensor([[0.0445]], dtype=torch.float64),\n",
       " tensor([[0.0002]], dtype=torch.float64),\n",
       " tensor([[0.0119]], dtype=torch.float64),\n",
       " tensor([[-0.0086]], dtype=torch.float64),\n",
       " tensor([[-0.0041]], dtype=torch.float64),\n",
       " tensor([[0.1081]], dtype=torch.float64),\n",
       " tensor([[-0.1891]], dtype=torch.float64),\n",
       " tensor([[-0.0010]], dtype=torch.float64),\n",
       " tensor([[0.0257]], dtype=torch.float64),\n",
       " tensor([[0.0031]], dtype=torch.float64),\n",
       " tensor([[-0.0006]], dtype=torch.float64),\n",
       " tensor([[-0.0035]], dtype=torch.float64),\n",
       " tensor([[0.0017]], dtype=torch.float64),\n",
       " tensor([[0.0445]], dtype=torch.float64),\n",
       " tensor([[0.0029]], dtype=torch.float64),\n",
       " tensor([[-0.0007]], dtype=torch.float64),\n",
       " tensor([[0.0019]], dtype=torch.float64),\n",
       " tensor([[0.0470]], dtype=torch.float64),\n",
       " tensor([[0.0005]], dtype=torch.float64),\n",
       " tensor([[-0.0036]], dtype=torch.float64),\n",
       " tensor([[0.0128]], dtype=torch.float64),\n",
       " tensor([[-0.0182]], dtype=torch.float64),\n",
       " tensor([[-0.0314]], dtype=torch.float64),\n",
       " tensor([[0.0009]], dtype=torch.float64),\n",
       " tensor([[-0.0111]], dtype=torch.float64),\n",
       " tensor([[0.0186]], dtype=torch.float64),\n",
       " tensor([[-0.0139]], dtype=torch.float64),\n",
       " tensor([[-0.0081]], dtype=torch.float64),\n",
       " tensor([[-0.0676]], dtype=torch.float64),\n",
       " tensor([[0.0184]], dtype=torch.float64),\n",
       " tensor([[-0.0028]], dtype=torch.float64),\n",
       " tensor([[0.0047]], dtype=torch.float64),\n",
       " tensor([[0.2127]], dtype=torch.float64),\n",
       " tensor([[0.0174]], dtype=torch.float64),\n",
       " tensor([[-0.0052]], dtype=torch.float64),\n",
       " tensor([[0.0004]], dtype=torch.float64),\n",
       " tensor([[0.0015]], dtype=torch.float64),\n",
       " tensor([[-0.0018]], dtype=torch.float64),\n",
       " tensor([[0.0217]], dtype=torch.float64),\n",
       " tensor([[0.0062]], dtype=torch.float64),\n",
       " tensor([[0.0074]], dtype=torch.float64),\n",
       " tensor([[0.0015]], dtype=torch.float64),\n",
       " tensor([[0.0059]], dtype=torch.float64),\n",
       " tensor([[6.6952e-06]], dtype=torch.float64),\n",
       " tensor([[-0.0012]], dtype=torch.float64),\n",
       " tensor([[-0.0160]], dtype=torch.float64),\n",
       " tensor([[0.0053]], dtype=torch.float64),\n",
       " tensor([[0.0004]], dtype=torch.float64),\n",
       " tensor([[-0.0005]], dtype=torch.float64),\n",
       " tensor([[0.0054]], dtype=torch.float64),\n",
       " tensor([[-0.0042]], dtype=torch.float64),\n",
       " tensor([[-0.0034]], dtype=torch.float64),\n",
       " tensor([[0.0251]], dtype=torch.float64),\n",
       " tensor([[-0.0057]], dtype=torch.float64),\n",
       " tensor([[0.4844]], dtype=torch.float64),\n",
       " tensor([[0.0264]], dtype=torch.float64),\n",
       " tensor([[0.0034]], dtype=torch.float64),\n",
       " tensor([[0.0013]], dtype=torch.float64),\n",
       " tensor([[0.0011]], dtype=torch.float64),\n",
       " tensor([[-0.0018]], dtype=torch.float64),\n",
       " tensor([[-0.0476]], dtype=torch.float64),\n",
       " tensor([[0.0065]], dtype=torch.float64),\n",
       " tensor([[-0.0001]], dtype=torch.float64),\n",
       " tensor([[0.0019]], dtype=torch.float64),\n",
       " tensor([[0.0196]], dtype=torch.float64),\n",
       " tensor([[-0.0564]], dtype=torch.float64),\n",
       " tensor([[-0.0066]], dtype=torch.float64),\n",
       " tensor([[0.0072]], dtype=torch.float64),\n",
       " tensor([[0.0150]], dtype=torch.float64),\n",
       " tensor([[-0.0019]], dtype=torch.float64),\n",
       " tensor([[-0.0661]], dtype=torch.float64),\n",
       " tensor([[-0.0319]], dtype=torch.float64),\n",
       " tensor([[0.0018]], dtype=torch.float64),\n",
       " tensor([[0.0019]], dtype=torch.float64),\n",
       " tensor([[0.0017]], dtype=torch.float64),\n",
       " tensor([[3.3279e-05]], dtype=torch.float64),\n",
       " tensor([[-0.0014]], dtype=torch.float64),\n",
       " tensor([[0.0624]], dtype=torch.float64),\n",
       " tensor([[0.0012]], dtype=torch.float64),\n",
       " tensor([[0.0129]], dtype=torch.float64),\n",
       " tensor([[-0.0888]], dtype=torch.float64),\n",
       " tensor([[-0.0070]], dtype=torch.float64),\n",
       " tensor([[-0.0060]], dtype=torch.float64),\n",
       " tensor([[-0.0156]], dtype=torch.float64),\n",
       " tensor([[0.0066]], dtype=torch.float64),\n",
       " tensor([[0.0004]], dtype=torch.float64),\n",
       " tensor([[-0.0219]], dtype=torch.float64),\n",
       " tensor([[0.0111]], dtype=torch.float64),\n",
       " tensor([[0.0057]], dtype=torch.float64),\n",
       " tensor([[0.0113]], dtype=torch.float64),\n",
       " tensor([[0.0026]], dtype=torch.float64),\n",
       " tensor([[-0.0004]], dtype=torch.float64),\n",
       " tensor([[-0.0377]], dtype=torch.float64),\n",
       " tensor([[-0.0012]], dtype=torch.float64),\n",
       " tensor([[-0.1188]], dtype=torch.float64),\n",
       " tensor([[0.0364]], dtype=torch.float64),\n",
       " tensor([[-0.3710]], dtype=torch.float64),\n",
       " tensor([[0.0017]], dtype=torch.float64),\n",
       " tensor([[-0.0224]], dtype=torch.float64),\n",
       " tensor([[0.0041]], dtype=torch.float64),\n",
       " tensor([[-0.0220]], dtype=torch.float64),\n",
       " tensor([[-0.0897]], dtype=torch.float64),\n",
       " tensor([[0.0627]], dtype=torch.float64),\n",
       " tensor([[-0.0255]], dtype=torch.float64),\n",
       " tensor([[-0.0047]], dtype=torch.float64),\n",
       " tensor([[-0.0075]], dtype=torch.float64),\n",
       " tensor([[0.0003]], dtype=torch.float64),\n",
       " tensor([[-0.0006]], dtype=torch.float64),\n",
       " tensor([[0.0023]], dtype=torch.float64),\n",
       " tensor([[-0.0005]], dtype=torch.float64),\n",
       " tensor([[-0.0034]], dtype=torch.float64),\n",
       " tensor([[0.0109]], dtype=torch.float64),\n",
       " tensor([[0.0030]], dtype=torch.float64),\n",
       " tensor([[-0.0126]], dtype=torch.float64),\n",
       " tensor([[-0.0441]], dtype=torch.float64),\n",
       " tensor([[-0.0250]], dtype=torch.float64),\n",
       " tensor([[-0.0018]], dtype=torch.float64),\n",
       " tensor([[-0.0277]], dtype=torch.float64),\n",
       " tensor([[-0.0163]], dtype=torch.float64),\n",
       " tensor([[-0.0453]], dtype=torch.float64),\n",
       " tensor([[0.0084]], dtype=torch.float64),\n",
       " tensor([[0.0650]], dtype=torch.float64),\n",
       " tensor([[0.0077]], dtype=torch.float64),\n",
       " tensor([[-0.0022]], dtype=torch.float64),\n",
       " tensor([[-0.0571]], dtype=torch.float64),\n",
       " tensor([[-0.0130]], dtype=torch.float64),\n",
       " tensor([[-0.0156]], dtype=torch.float64),\n",
       " tensor([[-0.1089]], dtype=torch.float64),\n",
       " tensor([[0.0035]], dtype=torch.float64),\n",
       " tensor([[0.0011]], dtype=torch.float64),\n",
       " tensor([[0.0021]], dtype=torch.float64),\n",
       " tensor([[0.0268]], dtype=torch.float64),\n",
       " tensor([[-0.0344]], dtype=torch.float64),\n",
       " tensor([[0.0124]], dtype=torch.float64),\n",
       " tensor([[-0.0069]], dtype=torch.float64),\n",
       " tensor([[-0.0024]], dtype=torch.float64),\n",
       " tensor([[-0.0480]], dtype=torch.float64),\n",
       " tensor([[-0.0040]], dtype=torch.float64),\n",
       " tensor([[0.0015]], dtype=torch.float64),\n",
       " tensor([[-0.1224]], dtype=torch.float64),\n",
       " tensor([[0.0270]], dtype=torch.float64),\n",
       " tensor([[-0.0054]], dtype=torch.float64),\n",
       " tensor([[-0.0069]], dtype=torch.float64),\n",
       " tensor([[2.2056e-05]], dtype=torch.float64),\n",
       " tensor([[-0.0171]], dtype=torch.float64),\n",
       " tensor([[0.0118]], dtype=torch.float64),\n",
       " tensor([[-0.0140]], dtype=torch.float64),\n",
       " tensor([[0.0059]], dtype=torch.float64),\n",
       " tensor([[0.0009]], dtype=torch.float64),\n",
       " tensor([[0.0026]], dtype=torch.float64),\n",
       " tensor([[0.0111]], dtype=torch.float64),\n",
       " tensor([[0.0047]], dtype=torch.float64),\n",
       " tensor([[-0.0424]], dtype=torch.float64),\n",
       " tensor([[-0.0220]], dtype=torch.float64),\n",
       " tensor([[0.0225]], dtype=torch.float64),\n",
       " tensor([[-0.0114]], dtype=torch.float64),\n",
       " tensor([[0.0001]], dtype=torch.float64),\n",
       " tensor([[0.0031]], dtype=torch.float64),\n",
       " tensor([[-0.0024]], dtype=torch.float64),\n",
       " tensor([[-0.0002]], dtype=torch.float64),\n",
       " tensor([[0.0011]], dtype=torch.float64),\n",
       " tensor([[-0.0552]], dtype=torch.float64),\n",
       " tensor([[-0.0130]], dtype=torch.float64),\n",
       " tensor([[0.0077]], dtype=torch.float64),\n",
       " tensor([[-0.1413]], dtype=torch.float64),\n",
       " tensor([[0.6724]], dtype=torch.float64),\n",
       " tensor([[0.0504]], dtype=torch.float64),\n",
       " tensor([[-0.0367]], dtype=torch.float64),\n",
       " tensor([[0.0065]], dtype=torch.float64),\n",
       " tensor([[0.0044]], dtype=torch.float64),\n",
       " tensor([[-0.0737]], dtype=torch.float64),\n",
       " tensor([[-0.0066]], dtype=torch.float64),\n",
       " tensor([[0.0014]], dtype=torch.float64),\n",
       " tensor([[0.0081]], dtype=torch.float64),\n",
       " tensor([[0.2275]], dtype=torch.float64),\n",
       " tensor([[0.0001]], dtype=torch.float64),\n",
       " tensor([[-0.0105]], dtype=torch.float64),\n",
       " tensor([[0.0223]], dtype=torch.float64),\n",
       " tensor([[0.0081]], dtype=torch.float64),\n",
       " tensor([[-0.0050]], dtype=torch.float64),\n",
       " tensor([[-1.3119]], dtype=torch.float64),\n",
       " tensor([[-0.0650]], dtype=torch.float64),\n",
       " tensor([[-0.0093]], dtype=torch.float64),\n",
       " tensor([[0.0018]], dtype=torch.float64),\n",
       " tensor([[-0.0029]], dtype=torch.float64),\n",
       " tensor([[0.0043]], dtype=torch.float64),\n",
       " tensor([[0.0053]], dtype=torch.float64),\n",
       " tensor([[-0.0484]], dtype=torch.float64),\n",
       " tensor([[-0.0057]], dtype=torch.float64),\n",
       " tensor([[-0.0036]], dtype=torch.float64),\n",
       " tensor([[-0.0042]], dtype=torch.float64),\n",
       " tensor([[0.0024]], dtype=torch.float64),\n",
       " tensor([[0.0015]], dtype=torch.float64),\n",
       " tensor([[-0.0434]], dtype=torch.float64),\n",
       " tensor([[-0.0007]], dtype=torch.float64),\n",
       " tensor([[-0.0706]], dtype=torch.float64),\n",
       " tensor([[-0.0051]], dtype=torch.float64),\n",
       " tensor([[-0.0452]], dtype=torch.float64),\n",
       " tensor([[-0.0067]], dtype=torch.float64),\n",
       " tensor([[0.0261]], dtype=torch.float64),\n",
       " tensor([[-0.1126]], dtype=torch.float64),\n",
       " tensor([[0.0037]], dtype=torch.float64),\n",
       " tensor([[0.0622]], dtype=torch.float64),\n",
       " tensor([[-0.0011]], dtype=torch.float64),\n",
       " tensor([[0.0086]], dtype=torch.float64),\n",
       " tensor([[-0.0145]], dtype=torch.float64),\n",
       " tensor([[0.0049]], dtype=torch.float64),\n",
       " tensor([[-0.0022]], dtype=torch.float64),\n",
       " tensor([[0.0015]], dtype=torch.float64),\n",
       " tensor([[0.0054]], dtype=torch.float64),\n",
       " tensor([[0.0022]], dtype=torch.float64),\n",
       " tensor([[-0.0035]], dtype=torch.float64),\n",
       " tensor([[0.0035]], dtype=torch.float64),\n",
       " tensor([[-0.0217]], dtype=torch.float64),\n",
       " tensor([[-0.0015]], dtype=torch.float64),\n",
       " tensor([[-0.0211]], dtype=torch.float64),\n",
       " tensor([[-0.0088]], dtype=torch.float64),\n",
       " tensor([[-0.0391]], dtype=torch.float64),\n",
       " tensor([[-0.0003]], dtype=torch.float64),\n",
       " tensor([[0.0014]], dtype=torch.float64),\n",
       " tensor([[0.0045]], dtype=torch.float64),\n",
       " tensor([[0.0289]], dtype=torch.float64),\n",
       " tensor([[0.0027]], dtype=torch.float64),\n",
       " tensor([[0.0052]], dtype=torch.float64),\n",
       " tensor([[0.0091]], dtype=torch.float64),\n",
       " tensor([[0.0007]], dtype=torch.float64),\n",
       " tensor([[-0.0011]], dtype=torch.float64),\n",
       " tensor([[-0.0002]], dtype=torch.float64),\n",
       " tensor([[0.0067]], dtype=torch.float64),\n",
       " tensor([[0.0398]], dtype=torch.float64),\n",
       " tensor([[-0.0043]], dtype=torch.float64),\n",
       " tensor([[-0.0011]], dtype=torch.float64),\n",
       " tensor([[0.0050]], dtype=torch.float64),\n",
       " tensor([[0.2688]], dtype=torch.float64),\n",
       " tensor([[0.0104]], dtype=torch.float64),\n",
       " tensor([[0.0019]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1082]], dtype=torch.float64)\n",
      "tensor([[0.0470]], dtype=torch.float64)\n",
      "tensor([[0.1152]], dtype=torch.float64)\n",
      "tensor([[-0.5336]], dtype=torch.float64)\n",
      "tensor([[-0.1843]], dtype=torch.float64)\n",
      "tensor([[0.0013]], dtype=torch.float64)\n",
      "tensor([[-0.0022]], dtype=torch.float64)\n",
      "tensor([[-0.0010]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "mean_tensor = torch.stack(errors_1).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_2).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_3).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_4).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_5).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_6).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_7).mean(dim=0)\n",
    "print(mean_tensor)\n",
    "mean_tensor = torch.stack(errors_8).mean(dim=0)\n",
    "\n",
    "print(mean_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "errors= []\n",
    "upper=[]\n",
    "predictions=[]\n",
    "for i, test_sample in enumerate(X_test_scaled):\n",
    "    indicies = get_closest_samples(X_scaled, test_sample, 1000)\n",
    "    model = Model(X_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    predictions.append(y_pred.to('cpu').reshape(-1))\n",
    "    upper.append(ucb.to('cpu'))\n",
    "    print(f\"Prediction: {y_pred}\")\n",
    "    print(f\"Uncertainty: {ucb-y_pred}\")\n",
    "    print(f\"real_value_error: {y_pred-torch.tensor(exp_y_test[i])}\")\n",
    "    errors.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "\n",
    "mean_tensor = torch.stack(errors).mean(dim=0)\n",
    "\n",
    "print(mean_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[6.9577]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0110]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0042]], dtype=torch.float64)\n",
      "Prediction: tensor([[-2.4362]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.2614]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0030]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.9581]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3205]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0272]], dtype=torch.float64)\n",
      "Prediction: tensor([[0.3032]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1648]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0184]], dtype=torch.float64)\n",
      "Prediction: tensor([[-73.8573]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0226]], dtype=torch.float64)\n",
      "Prediction: tensor([[2.0835]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5339]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0049]], dtype=torch.float64)\n",
      "Prediction: tensor([[1.4611]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3950]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.1055]], dtype=torch.float64)\n",
      "Prediction: tensor([[-19.3583]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0589]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0069]], dtype=torch.float64)\n",
      "Prediction: tensor([[17.3488]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4047]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0015]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.4885]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4047]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0729]], dtype=torch.float64)\n",
      "Prediction: tensor([[6.6149]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3820]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0080]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.5132]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4030]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0130]], dtype=torch.float64)\n",
      "Prediction: tensor([[8.5369]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3030]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0125]], dtype=torch.float64)\n",
      "Prediction: tensor([[-4.3754]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0085]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0192]], dtype=torch.float64)\n",
      "Prediction: tensor([[14.7939]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2608]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0053]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.7130]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5529]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.1173]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.4268]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3729]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0301]], dtype=torch.float64)\n",
      "Prediction: tensor([[-4.9024]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0160]], dtype=torch.float64)\n",
      "Prediction: tensor([[-21.5351]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5282]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.3214]], dtype=torch.float64)\n",
      "Prediction: tensor([[18.1643]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1691]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0615]], dtype=torch.float64)\n",
      "Prediction: tensor([[8.4022]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2783]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0098]], dtype=torch.float64)\n",
      "Prediction: tensor([[-15.1908]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0192]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0118]], dtype=torch.float64)\n",
      "Prediction: tensor([[11.3488]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1976]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0902]], dtype=torch.float64)\n",
      "Prediction: tensor([[10.8469]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3679]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0241]], dtype=torch.float64)\n",
      "Prediction: tensor([[4.6392]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0155]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0261]], dtype=torch.float64)\n",
      "Prediction: tensor([[14.4759]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1923]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0028]], dtype=torch.float64)\n",
      "Prediction: tensor([[6.9992]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0535]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0232]], dtype=torch.float64)\n",
      "Prediction: tensor([[11.7393]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0061]], dtype=torch.float64)\n",
      "Prediction: tensor([[2.0020]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1553]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0036]], dtype=torch.float64)\n",
      "Prediction: tensor([[7.1482]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.1326]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0115]], dtype=torch.float64)\n",
      "Prediction: tensor([[3.6110]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-4.3800]], dtype=torch.float64)\n",
      "Prediction: tensor([[-1.3823]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0673]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0095]], dtype=torch.float64)\n",
      "Prediction: tensor([[3.2817]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3191]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0098]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.0864]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.5038]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0240]], dtype=torch.float64)\n",
      "Prediction: tensor([[-6.8919]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2585]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.1170]], dtype=torch.float64)\n",
      "Prediction: tensor([[-3.6291]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0129]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0005]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.9404]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0119]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0275]], dtype=torch.float64)\n",
      "Prediction: tensor([[10.2396]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.4131]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0284]], dtype=torch.float64)\n",
      "Prediction: tensor([[-5.9631]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0064]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0018]], dtype=torch.float64)\n",
      "Prediction: tensor([[14.8431]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2472]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0696]], dtype=torch.float64)\n",
      "Prediction: tensor([[16.6159]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3116]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0452]], dtype=torch.float64)\n",
      "Prediction: tensor([[-17.5608]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2755]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0092]], dtype=torch.float64)\n",
      "Prediction: tensor([[4.3801]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.6539]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0034]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.1659]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0117]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.0064]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0119]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0027]], dtype=torch.float64)\n",
      "Prediction: tensor([[8.5282]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.3246]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0051]], dtype=torch.float64)\n",
      "Prediction: tensor([[-0.7752]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0280]], dtype=torch.float64)\n",
      "Prediction: tensor([[17.1390]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2071]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0030]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.0733]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.2647]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.0389]], dtype=torch.float64)\n",
      "Prediction: tensor([[0.2359]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[0.0138]], dtype=torch.float64)\n",
      "real_value_error: tensor([[0.0379]], dtype=torch.float64)\n",
      "tensor([[-0.0860]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "errors= []\n",
    "upper=[]\n",
    "predictions=[]\n",
    "for i, test_sample in enumerate(X_test_scaled):\n",
    "    indicies = get_closest_samples(X_scaled, test_sample, 1000)\n",
    "    model = Model(X_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "    model.fit(epochs=1, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    predictions.append(y_pred.to('cpu').reshape(-1))\n",
    "    upper.append(ucb.to('cpu'))\n",
    "    print(f\"Prediction: {y_pred}\")\n",
    "    print(f\"Uncertainty: {ucb-y_pred}\")\n",
    "    print(f\"real_value_error: {y_pred-torch.tensor(exp_y_test[i])}\")\n",
    "    errors.append(y_pred-torch.tensor(exp_y_test[i]))\n",
    "\n",
    "mean_tensor = torch.stack(errors).mean(dim=0)\n",
    "\n",
    "print(mean_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0110]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "mean_tensor = torch.stack(errors).mean(dim=0)\n",
    "\n",
    "print(mean_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [00:01<00:00,  1.43it/s, loss=9.17, lr=1.000E-04, noise=3.42e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[5.4055]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[3.5921]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-1.5564]], dtype=torch.float64)\n",
      "Prediction: tensor([[-0.6363]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[2.3670]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-7.5981]], dtype=torch.float64)\n",
      "Prediction: tensor([[9.9097]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.5413]], dtype=torch.float64)\n",
      "real_value_error: tensor([[2.9479]], dtype=torch.float64)\n",
      "Prediction: tensor([[6.0141]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[4.7867]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-0.9478]], dtype=torch.float64)\n",
      "Prediction: tensor([[-32.3952]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[10.9033]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-39.3571]], dtype=torch.float64)\n",
      "Prediction: tensor([[0.4403]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[8.3269]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-6.5216]], dtype=torch.float64)\n",
      "Prediction: tensor([[-7.1731]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[7.5086]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-14.1350]], dtype=torch.float64)\n",
      "Prediction: tensor([[-15.4621]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[12.8326]], dtype=torch.float64)\n",
      "real_value_error: tensor([[-22.4240]], dtype=torch.float64)\n",
      "Prediction: tensor([[17.1105]], dtype=torch.float64)\n",
      "Uncertainty: tensor([[1.4664]], dtype=torch.float64)\n",
      "real_value_error: tensor([[10.1486]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m X_test_scaled:\n\u001b[0;32m     12\u001b[0m     loaded_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/model_test.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     y_pred, lcb, ucb \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\model.py:39\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, pred_var)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predict\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_var\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet backend name to \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m or  \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m in config.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\models.py:344\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, x, pred_var)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), settings\u001b[38;5;241m.\u001b[39mfast_pred_var():\n\u001b[1;32m--> 344\u001b[0m         posterior \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pred_var:\n\u001b[0;32m    346\u001b[0m             lower, upper \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mmvn\u001b[38;5;241m.\u001b[39mconfidence_region()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\botorch\\models\\gpytorch.py:399\u001b[0m, in \u001b[0;36mBatchedMultiOutputGPyTorchModel.posterior\u001b[1;34m(self, X, output_indices, observation_noise, posterior_transform)\u001b[0m\n\u001b[0;32m    393\u001b[0m     X, output_dim_idx \u001b[38;5;241m=\u001b[39m add_output_dim(\n\u001b[0;32m    394\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, original_batch_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_batch_shape\n\u001b[0;32m    395\u001b[0m     )\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# NOTE: BoTorch's GPyTorchModels also inherit from GPyTorch's ExactGP, thus\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;66;03m# self(X) calls GPyTorch's ExactGP's __call__, which computes the posterior,\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# rather than e.g. SingleTaskGP's forward, which computes the prior.\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m mvn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\models.py:232\u001b[0m, in \u001b[0;36mCovNet.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mcg_tolerance(settings\u001b[38;5;241m.\u001b[39meval_cg_tolerance\u001b[38;5;241m.\u001b[39mvalue()):\n\u001b[0;32m    229\u001b[0m     (\n\u001b[0;32m    230\u001b[0m         predictive_mean,\n\u001b[0;32m    231\u001b[0m         predictive_covar,\n\u001b[1;32m--> 232\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[0;32m    235\u001b[0m predictive_mean \u001b[38;5;241m=\u001b[39m predictive_mean\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtest_shape)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:290\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[1;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[0;32m    285\u001b[0m     test_test_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :]\n\u001b[0;32m    286\u001b[0m     test_train_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train]\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexact_predictive_mean(test_mean, test_train_covar),\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_predictive_covar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_test_covar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_covar\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    291\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:356\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_covar\u001b[1;34m(self, test_test_covar, test_train_covar)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;66;03m# In other cases - we'll use the standard infrastructure\u001b[39;00m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m test_test_covar \u001b[38;5;241m+\u001b[39m MatmulLinearOperator(test_train_covar, covar_correction_rhs\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 356\u001b[0m precomputed_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar_cache\u001b[49m\n\u001b[0;32m    357\u001b[0m covar_inv_quad_form_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exact_predictive_covar_inv_quad_form_root(precomputed_cache, test_train_covar)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(test_test_covar):\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:246\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.covar_cache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;129m@cached\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovar_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcovar_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    245\u001b[0m     train_train_covar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlik_train_train_covar\n\u001b[1;32m--> 246\u001b[0m     train_train_covar_inv_root \u001b[38;5;241m=\u001b[39m to_dense(\u001b[43mtrain_train_covar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_inv_decomposition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exact_predictive_covar_inv_quad_form_cache(train_train_covar_inv_root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_test_train_covar)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:2225\u001b[0m, in \u001b[0;36mLinearOperator.root_inv_decomposition\u001b[1;34m(self, initial_vectors, test_vectors, method)\u001b[0m\n\u001b[0;32m   2222\u001b[0m \u001b[38;5;66;03m# we know L is triangular, so inverting is a simple triangular solve agaist the identity\u001b[39;00m\n\u001b[0;32m   2223\u001b[0m \u001b[38;5;66;03m# we don't need the batch shape here, thanks to broadcasting\u001b[39;00m\n\u001b[0;32m   2224\u001b[0m Eye \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(L\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], device\u001b[38;5;241m=\u001b[39mL\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mL\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m-> 2225\u001b[0m Linv \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_triangular\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEye\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2226\u001b[0m res \u001b[38;5;241m=\u001b[39m to_linear_operator(Linv\u001b[38;5;241m.\u001b[39mmT)\n\u001b[0;32m   2227\u001b[0m inv_root \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cluster_labels_series = pd.Series(cluster_labels)\n",
    "for i in range(50):\n",
    "    indices = cluster_labels_series == i\n",
    "    batch = X_test_scaled[indices]\n",
    "    centroid = centroids[i]\n",
    "    train_indices = get_closest_samples(X_scaled, centroid)\n",
    "    model = Model(X_scaled[train_indices], exp_y_train[train_indices], noise=False, batch_size=1024, neurons=200, learning_rate=1e-4)\n",
    "    model.fit(epochs=2, verbose=True)\n",
    "    torch.save(model, f'models/model_test.pth')\n",
    "    predictions= []\n",
    "    for sample in X_test_scaled:\n",
    "        loaded_model = torch.load(f'models/model_test.pth')\n",
    "        y_pred, lcb, ucb = loaded_model.predict(sample.reshape(1,-1), pred_var=True)\n",
    "        predictions.append(y_pred.cpu().reshape(1))\n",
    "        print(f\"Prediction: {y_pred}\")\n",
    "        print(f\"Uncertainty: {ucb-y_pred}\")\n",
    "        print(f\"real_value_error: {y_pred-torch.tensor(exp_y_test[i])}\")\n",
    "        del loaded_model\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.53858789, -1.315308  ,  1.10895045, ...,  1.39992477,\n",
       "         0.6622477 ,  0.2403719 ],\n",
       "       [ 0.22653748,  0.67254894, -0.22913171, ..., -0.46368323,\n",
       "         0.68758428, -0.52633797],\n",
       "       [ 0.63019948,  1.07857027,  0.87557534, ..., -1.34881169,\n",
       "         0.64896926,  0.04613893],\n",
       "       ...,\n",
       "       [ 1.18476316,  1.93090512,  1.53291891, ..., -0.32348001,\n",
       "         0.67357278,  0.27309396],\n",
       "       [-0.62521868,  0.62915735, -1.12027216, ..., -0.83398767,\n",
       "         0.67607484, -1.19286747],\n",
       "       [-0.37158191,  0.74749806, -0.63527559, ..., -0.32669053,\n",
       "         0.67698467, -0.93483203]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:12<00:00, 12.66s/it, loss=10.9, lr=1.000E-04, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.949914947049579e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 1/1 [00:12<00:00, 12.38s/it, loss=4.19, lr=1.000E-04, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 3.760940669708708e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 1/1 [00:12<00:00, 12.33s/it, loss=3.79, lr=1.000E-04, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 7.373646652974687e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 1/1 [00:12<00:00, 12.55s/it, loss=3.79, lr=1.000E-04, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 0.0016175500247224586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 1/1 [00:12<00:00, 12.32s/it, loss=3.79, lr=1.000E-04, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 0.0050524391476480714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 1/1 [00:12<00:00, 12.34s/it, loss=3.82, lr=1.000E-04, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: 0.09921345325621836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch:   0%|          | 0/1 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(X_np[:\u001b[38;5;241m700000\u001b[39m], y_trq_np[:\u001b[38;5;241m700000\u001b[39m], noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, neurons\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m     predictions\u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\model.py:30\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, epochs, delete_weights, verbose)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fit\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet backend name to \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m or  \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m in config.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\models.py:295\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, epochs, verbose)\u001b[0m\n\u001b[0;32m    293\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[0;32m    294\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmll(output, y_batch\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m--> 295\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    297\u001b[0m reducer\u001b[38;5;241m.\u001b[39mstep(loss)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "model = Model(X_np[:700000], y_trq_np[:700000], noise=False, batch_size=1024, neurons=200, learning_rate=1e-4)\n",
    "for epoch in range(n_epochs):\n",
    "    model.fit(epochs=1, verbose=True)\n",
    "    torch.save(model, f'models/model_{epoch}.pth')\n",
    "    predictions= []\n",
    "    for sample in X_np[700000:700100]:\n",
    "        loaded_model = torch.load(f'models/model_{epoch}.pth')\n",
    "        y_pred = loaded_model.predict(sample.reshape(1,-1))\n",
    "        predictions.append(y_pred.cpu().reshape(1))\n",
    "\n",
    "    mse = mean_squared_error(np.array(predictions), y_trq_np[700000:700100])\n",
    "    print(f\"{epoch}: {mse}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006916857582440312\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(predictions, y_trq_np[700000:700263])\n",
    "print(f\"{mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:tensor([[6.9598]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0020]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[-2.4383]], dtype=torch.float64)\n",
      "reak:tensor([[0.0009]], dtype=torch.float64)\n",
      "uncertainty:tensor([[5.6702]], dtype=torch.float64)\n",
      "pred:tensor([[9.9809]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0043]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.6373]], dtype=torch.float64)\n",
      "pred:tensor([[0.2789]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0059]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.7949]], dtype=torch.float64)\n",
      "pred:tensor([[-73.8792]], dtype=torch.float64)\n",
      "reak:tensor([[0.0007]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.0528]], dtype=torch.float64)\n",
      "pred:tensor([[2.0888]], dtype=torch.float64)\n",
      "reak:tensor([[0.0004]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.3447]], dtype=torch.float64)\n",
      "pred:tensor([[1.5661]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0006]], dtype=torch.float64)\n",
      "uncertainty:tensor([[5.4194]], dtype=torch.float64)\n",
      "pred:tensor([[-19.3519]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0005]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.8886]], dtype=torch.float64)\n",
      "pred:tensor([[17.3501]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0002]], dtype=torch.float64)\n",
      "uncertainty:tensor([[3.9964]], dtype=torch.float64)\n",
      "pred:tensor([[7.4149]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0007]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.7768]], dtype=torch.float64)\n",
      "pred:tensor([[6.6091]], dtype=torch.float64)\n",
      "reak:tensor([[0.0022]], dtype=torch.float64)\n",
      "uncertainty:tensor([[3.9544]], dtype=torch.float64)\n",
      "pred:tensor([[9.5309]], dtype=torch.float64)\n",
      "reak:tensor([[0.0047]], dtype=torch.float64)\n",
      "uncertainty:tensor([[4.4206]], dtype=torch.float64)\n",
      "pred:tensor([[8.5242]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0003]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.4457]], dtype=torch.float64)\n",
      "pred:tensor([[-4.3563]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0002]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[14.7896]], dtype=torch.float64)\n",
      "reak:tensor([[0.0009]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.3760]], dtype=torch.float64)\n",
      "pred:tensor([[9.8234]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0068]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.2597]], dtype=torch.float64)\n",
      "pred:tensor([[9.4554]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0015]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.9950]], dtype=torch.float64)\n",
      "pred:tensor([[-4.9189]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0005]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[-21.8164]], dtype=torch.float64)\n",
      "reak:tensor([[0.0400]], dtype=torch.float64)\n",
      "uncertainty:tensor([[6.3961]], dtype=torch.float64)\n",
      "pred:tensor([[18.2270]], dtype=torch.float64)\n",
      "reak:tensor([[0.0011]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.8057]], dtype=torch.float64)\n",
      "pred:tensor([[8.3792]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0132]], dtype=torch.float64)\n",
      "uncertainty:tensor([[6.2373]], dtype=torch.float64)\n",
      "pred:tensor([[-15.1807]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0017]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.3147]], dtype=torch.float64)\n",
      "pred:tensor([[11.4392]], dtype=torch.float64)\n",
      "reak:tensor([[0.0003]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.6338]], dtype=torch.float64)\n",
      "pred:tensor([[10.8599]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0112]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.6043]], dtype=torch.float64)\n",
      "pred:tensor([[4.6132]], dtype=torch.float64)\n",
      "reak:tensor([[3.4082e-05]], dtype=torch.float64)\n",
      "uncertainty:tensor([[0.0104]], dtype=torch.float64)\n",
      "pred:tensor([[14.4740]], dtype=torch.float64)\n",
      "reak:tensor([[0.0009]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.8423]], dtype=torch.float64)\n",
      "pred:tensor([[7.0212]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0012]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.8703]], dtype=torch.float64)\n",
      "pred:tensor([[11.7452]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0002]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.1782]], dtype=torch.float64)\n",
      "pred:tensor([[2.0041]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0015]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.8693]], dtype=torch.float64)\n",
      "pred:tensor([[7.1591]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0006]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.8801]], dtype=torch.float64)\n",
      "pred:tensor([[7.9892]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0018]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.8736]], dtype=torch.float64)\n",
      "pred:tensor([[-1.3768]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0040]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.5262]], dtype=torch.float64)\n",
      "pred:tensor([[3.2716]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0003]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.3312]], dtype=torch.float64)\n",
      "pred:tensor([[9.1108]], dtype=torch.float64)\n",
      "reak:tensor([[0.0004]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.7209]], dtype=torch.float64)\n",
      "pred:tensor([[-7.0113]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0024]], dtype=torch.float64)\n",
      "uncertainty:tensor([[4.8191]], dtype=torch.float64)\n",
      "pred:tensor([[-3.6286]], dtype=torch.float64)\n",
      "reak:tensor([[3.3915e-05]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[-7.9170]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0041]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[10.2702]], dtype=torch.float64)\n",
      "reak:tensor([[0.0022]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.7022]], dtype=torch.float64)\n",
      "pred:tensor([[-5.9620]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0006]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[14.7737]], dtype=torch.float64)\n",
      "reak:tensor([[0.0002]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.7970]], dtype=torch.float64)\n",
      "pred:tensor([[16.5709]], dtype=torch.float64)\n",
      "reak:tensor([[0.0002]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0347]], dtype=torch.float64)\n",
      "pred:tensor([[-17.5536]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0019]], dtype=torch.float64)\n",
      "uncertainty:tensor([[4.3452]], dtype=torch.float64)\n",
      "pred:tensor([[4.3732]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0103]], dtype=torch.float64)\n",
      "uncertainty:tensor([[3.5557]], dtype=torch.float64)\n",
      "pred:tensor([[-7.1783]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0007]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[-7.0042]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0005]], dtype=torch.float64)\n",
      "uncertainty:tensor([[0.0231]], dtype=torch.float64)\n",
      "pred:tensor([[8.5222]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0009]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.3651]], dtype=torch.float64)\n",
      "pred:tensor([[-0.7499]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0026]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[17.1364]], dtype=torch.float64)\n",
      "reak:tensor([[0.0004]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.4686]], dtype=torch.float64)\n",
      "pred:tensor([[-7.0352]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0008]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0189]], dtype=torch.float64)\n",
      "pred:tensor([[0.1973]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0007]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[11.3567]], dtype=torch.float64)\n",
      "reak:tensor([[0.0035]], dtype=torch.float64)\n",
      "uncertainty:tensor([[3.1325]], dtype=torch.float64)\n",
      "pred:tensor([[-6.9606]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0009]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[5.6102]], dtype=torch.float64)\n",
      "reak:tensor([[0.0082]], dtype=torch.float64)\n",
      "uncertainty:tensor([[5.6933]], dtype=torch.float64)\n",
      "pred:tensor([[7.7350]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0002]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.2241]], dtype=torch.float64)\n",
      "pred:tensor([[-13.6353]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0017]], dtype=torch.float64)\n",
      "uncertainty:tensor([[4.5535]], dtype=torch.float64)\n",
      "pred:tensor([[-20.0271]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0022]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.7814]], dtype=torch.float64)\n",
      "pred:tensor([[2.6810]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0010]], dtype=torch.float64)\n",
      "uncertainty:tensor([[3.8584]], dtype=torch.float64)\n",
      "pred:tensor([[8.2020]], dtype=torch.float64)\n",
      "reak:tensor([[0.0003]], dtype=torch.float64)\n",
      "uncertainty:tensor([[3.2018]], dtype=torch.float64)\n",
      "pred:tensor([[-18.8792]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0005]], dtype=torch.float64)\n",
      "uncertainty:tensor([[0.7877]], dtype=torch.float64)\n",
      "pred:tensor([[13.0105]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0002]], dtype=torch.float64)\n",
      "uncertainty:tensor([[1.0595]], dtype=torch.float64)\n",
      "pred:tensor([[-12.3950]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0002]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.9248]], dtype=torch.float64)\n",
      "pred:tensor([[-6.2574]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0001]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[-4.0348]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0003]], dtype=torch.float64)\n",
      "uncertainty:tensor([[3.2600]], dtype=torch.float64)\n",
      "pred:tensor([[7.6817]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0030]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.8700]], dtype=torch.float64)\n",
      "pred:tensor([[24.2318]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0123]], dtype=torch.float64)\n",
      "uncertainty:tensor([[2.0000e-05]], dtype=torch.float64)\n",
      "pred:tensor([[2.2336]], dtype=torch.float64)\n",
      "reak:tensor([[-0.0040]], dtype=torch.float64)\n",
      "uncertainty:tensor([[4.1920]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Convert the sample to a PyTorch tensor and move it to the appropriate device\u001b[39;00m\n\u001b[0;32m     13\u001b[0m sample_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(sample)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m y_pred, lcb, ucb \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Move prediction to CPU and convert to numpy\u001b[39;00m\n\u001b[0;32m     18\u001b[0m predictions\u001b[38;5;241m.\u001b[39mappend(y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\model.py:39\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, pred_var)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predict\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_var\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet backend name to \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m or  \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m in config.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\models.py:344\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, x, pred_var)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), settings\u001b[38;5;241m.\u001b[39mfast_pred_var():\n\u001b[1;32m--> 344\u001b[0m         posterior \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pred_var:\n\u001b[0;32m    346\u001b[0m             lower, upper \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mmvn\u001b[38;5;241m.\u001b[39mconfidence_region()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\botorch\\models\\gpytorch.py:399\u001b[0m, in \u001b[0;36mBatchedMultiOutputGPyTorchModel.posterior\u001b[1;34m(self, X, output_indices, observation_noise, posterior_transform)\u001b[0m\n\u001b[0;32m    393\u001b[0m     X, output_dim_idx \u001b[38;5;241m=\u001b[39m add_output_dim(\n\u001b[0;32m    394\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, original_batch_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_batch_shape\n\u001b[0;32m    395\u001b[0m     )\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# NOTE: BoTorch's GPyTorchModels also inherit from GPyTorch's ExactGP, thus\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;66;03m# self(X) calls GPyTorch's ExactGP's __call__, which computes the posterior,\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# rather than e.g. SingleTaskGP's forward, which computes the prior.\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m mvn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\models.py:232\u001b[0m, in \u001b[0;36mCovNet.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mcg_tolerance(settings\u001b[38;5;241m.\u001b[39meval_cg_tolerance\u001b[38;5;241m.\u001b[39mvalue()):\n\u001b[0;32m    229\u001b[0m     (\n\u001b[0;32m    230\u001b[0m         predictive_mean,\n\u001b[0;32m    231\u001b[0m         predictive_covar,\n\u001b[1;32m--> 232\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[0;32m    235\u001b[0m predictive_mean \u001b[38;5;241m=\u001b[39m predictive_mean\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtest_shape)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:290\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[1;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[0;32m    285\u001b[0m     test_test_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :]\n\u001b[0;32m    286\u001b[0m     test_train_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train]\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexact_predictive_mean(test_mean, test_train_covar),\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_predictive_covar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_test_covar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_covar\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    291\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:356\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_covar\u001b[1;34m(self, test_test_covar, test_train_covar)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;66;03m# In other cases - we'll use the standard infrastructure\u001b[39;00m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m test_test_covar \u001b[38;5;241m+\u001b[39m MatmulLinearOperator(test_train_covar, covar_correction_rhs\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 356\u001b[0m precomputed_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar_cache\u001b[49m\n\u001b[0;32m    357\u001b[0m covar_inv_quad_form_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exact_predictive_covar_inv_quad_form_root(precomputed_cache, test_train_covar)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(test_test_covar):\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:246\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.covar_cache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;129m@cached\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovar_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcovar_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    245\u001b[0m     train_train_covar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlik_train_train_covar\n\u001b[1;32m--> 246\u001b[0m     train_train_covar_inv_root \u001b[38;5;241m=\u001b[39m to_dense(\u001b[43mtrain_train_covar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_inv_decomposition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exact_predictive_covar_inv_quad_form_cache(train_train_covar_inv_root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_test_train_covar)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:2221\u001b[0m, in \u001b[0;36mLinearOperator.root_inv_decomposition\u001b[1;34m(self, initial_vectors, test_vectors, method)\u001b[0m\n\u001b[0;32m   2217\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_choose_root_method()\n\u001b[0;32m   2219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcholesky\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2220\u001b[0m     \u001b[38;5;66;03m# self.cholesky will hit cache if available\u001b[39;00m\n\u001b[1;32m-> 2221\u001b[0m     L \u001b[38;5;241m=\u001b[39m to_dense(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2222\u001b[0m     \u001b[38;5;66;03m# we know L is triangular, so inverting is a simple triangular solve agaist the identity\u001b[39;00m\n\u001b[0;32m   2223\u001b[0m     \u001b[38;5;66;03m# we don't need the batch shape here, thanks to broadcasting\u001b[39;00m\n\u001b[0;32m   2224\u001b[0m     Eye \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(L\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], device\u001b[38;5;241m=\u001b[39mL\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mL\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:1303\u001b[0m, in \u001b[0;36mLinearOperator.cholesky\u001b[1;34m(self, upper)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;129m@_implements\u001b[39m(torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky)\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcholesky\u001b[39m(\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;28mself\u001b[39m: Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch N N\u001b[39m\u001b[38;5;124m\"\u001b[39m], upper: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch N N\u001b[39m\u001b[38;5;124m\"\u001b[39m]:  \u001b[38;5;66;03m# returns TriangularLinearOperator\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;124;03m    Cholesky-factorizes the LinearOperator.\u001b[39;00m\n\u001b[0;32m   1299\u001b[0m \n\u001b[0;32m   1300\u001b[0m \u001b[38;5;124;03m    :param upper: Upper triangular or lower triangular factor (default: False).\u001b[39;00m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m    :return: Cholesky factor (lower or upper triangular)\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1303\u001b[0m     chol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m upper:\n\u001b[0;32m   1305\u001b[0m         chol \u001b[38;5;241m=\u001b[39m chol\u001b[38;5;241m.\u001b[39m_transpose_nonbatch()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:522\u001b[0m, in \u001b[0;36mLinearOperator._cholesky\u001b[1;34m(self, upper)\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TriangularLinearOperator(evaluated_mat\u001b[38;5;241m.\u001b[39mclamp_min(\u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39msqrt())\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# contiguous call is necessary here\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m cholesky \u001b[38;5;241m=\u001b[39m \u001b[43mpsd_safe_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluated_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TriangularLinearOperator(cholesky, upper\u001b[38;5;241m=\u001b[39mupper)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:65\u001b[0m, in \u001b[0;36mpsd_safe_cholesky\u001b[1;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpsd_safe_cholesky\u001b[39m(A, upper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, jitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_tries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the Cholesky decomposition of A. If A is only p.s.d, add a small jitter to the diagonal.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m        :attr:`A` (Tensor):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m            Number of attempts (with successively increasing jitter) to make before raising an error.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43m_psd_safe_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjitter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m upper:\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:44\u001b[0m, in \u001b[0;36m_psd_safe_cholesky\u001b[1;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[0;32m     39\u001b[0m jitter_prev \u001b[38;5;241m=\u001b[39m jitter_new\n\u001b[0;32m     40\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA not p.d., added jitter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjitter_new\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to the diagonal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m     NumericalWarning,\n\u001b[0;32m     43\u001b[0m )\n\u001b[1;32m---> 44\u001b[0m L, info \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAprime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(info):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m L\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "\n",
    "predictions = []\n",
    "for i, sample in enumerate(X_np[700000:700500]):\n",
    "    # Load the model and move it to the appropriate device\n",
    "    loaded_model = torch.load('models/model_1.pth', map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "    # Convert the sample to a PyTorch tensor and move it to the appropriate device\n",
    "    sample_tensor = torch.tensor(sample).float().unsqueeze(0)\n",
    "\n",
    "\n",
    "    y_pred, lcb, ucb = loaded_model.predict(sample_tensor, pred_var=True)  # Move prediction to CPU and convert to numpy\n",
    "\n",
    "    predictions.append(y_pred.cpu().reshape(1))\n",
    "    print(f\"pred:{y_pred}\")\n",
    "    print(f\"reak:{y_pred-y_trq_np[700000:700500][i]}\")\n",
    "    print(f\"uncertainty:{ucb-y_pred}\")\n",
    "\n",
    "    # Clean up to free memory\n",
    "    del loaded_model\n",
    "    del sample_tensor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# Convert predictions to numpy array\n",
    "predictions = np.array(predictions).reshape(-1)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(predictions, y_trq_np[700000:700500])\n",
    "print(f\"{epoch}: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m X_np[\u001b[38;5;241m700000\u001b[39m:\u001b[38;5;241m700500\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     loaded_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/model_1.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      6\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(np\u001b[38;5;241m.\u001b[39marray(predictions), y_trq_np[\u001b[38;5;241m700000\u001b[39m:\u001b[38;5;241m700100\u001b[39m])\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\model.py:39\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, pred_var)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predict\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_var\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet backend name to \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m or  \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mbotorch\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m in config.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\models.py:344\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, x, pred_var)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), settings\u001b[38;5;241m.\u001b[39mfast_pred_var():\n\u001b[1;32m--> 344\u001b[0m         posterior \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pred_var:\n\u001b[0;32m    346\u001b[0m             lower, upper \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mmvn\u001b[38;5;241m.\u001b[39mconfidence_region()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\botorch\\models\\gpytorch.py:399\u001b[0m, in \u001b[0;36mBatchedMultiOutputGPyTorchModel.posterior\u001b[1;34m(self, X, output_indices, observation_noise, posterior_transform)\u001b[0m\n\u001b[0;32m    393\u001b[0m     X, output_dim_idx \u001b[38;5;241m=\u001b[39m add_output_dim(\n\u001b[0;32m    394\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, original_batch_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_batch_shape\n\u001b[0;32m    395\u001b[0m     )\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# NOTE: BoTorch's GPyTorchModels also inherit from GPyTorch's ExactGP, thus\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;66;03m# self(X) calls GPyTorch's ExactGP's __call__, which computes the posterior,\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# rather than e.g. SingleTaskGP's forward, which computes the prior.\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m mvn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\models.py:232\u001b[0m, in \u001b[0;36mCovNet.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mcg_tolerance(settings\u001b[38;5;241m.\u001b[39meval_cg_tolerance\u001b[38;5;241m.\u001b[39mvalue()):\n\u001b[0;32m    229\u001b[0m     (\n\u001b[0;32m    230\u001b[0m         predictive_mean,\n\u001b[0;32m    231\u001b[0m         predictive_covar,\n\u001b[1;32m--> 232\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[0;32m    235\u001b[0m predictive_mean \u001b[38;5;241m=\u001b[39m predictive_mean\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtest_shape)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:289\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[1;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[0;32m    285\u001b[0m     test_test_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :]\n\u001b[0;32m    286\u001b[0m     test_train_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train]\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_predictive_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_covar\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexact_predictive_covar(test_test_covar, test_train_covar),\n\u001b[0;32m    291\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:306\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_mean\u001b[1;34m(self, test_mean, test_train_covar)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03mComputes the posterior predictive covariance of a GP\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;124;03m:return: The predictive posterior mean of the test points\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# NOTE TO FUTURE SELF:\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# You **cannot* use addmv here, because test_train_covar may not actually be a non lazy tensor even for an exact\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# GP, and using addmv requires you to to_dense test_train_covar, which is obviously a huge no-no!\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_cache\u001b[49m\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    307\u001b[0m     res \u001b[38;5;241m=\u001b[39m (test_train_covar \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_cache\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:256\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.mean_cache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m train_mean, train_train_covar \u001b[38;5;241m=\u001b[39m mvn\u001b[38;5;241m.\u001b[39mloc, mvn\u001b[38;5;241m.\u001b[39mlazy_covariance_matrix\n\u001b[0;32m    255\u001b[0m train_labels_offset \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels \u001b[38;5;241m-\u001b[39m train_mean)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 256\u001b[0m mean_cache \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_train_covar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msolve(train_labels_offset)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mdetach_test_caches\u001b[38;5;241m.\u001b[39mon():\n\u001b[0;32m    259\u001b[0m     mean_cache \u001b[38;5;241m=\u001b[39m mean_cache\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_grad_enabled):\n\u001b[1;32m---> 25\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\kernels\\kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[0;32m    527\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[1;32m--> 530\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\kernels.py:46\u001b[0m, in \u001b[0;36mDeepSumKernel.forward\u001b[1;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[0;32m     44\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mls1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ls1[:, i, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m     45\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mls2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ls2[:, i, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m---> 46\u001b[0m next_term \u001b[38;5;241m=\u001b[39m \u001b[43mkern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m diag:\n\u001b[0;32m     48\u001b[0m     k \u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m+\u001b[39m to_linear_operator(next_term)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\kernels\\kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[0;32m    527\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[1;32m--> 530\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mC:\\Projects/covnet2\\pt\\kernels.py:98\u001b[0m, in \u001b[0;36mDeepMaternKernel.forward\u001b[1;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[0;32m     96\u001b[0m     constant_component \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.5\u001b[39m:\n\u001b[1;32m---> 98\u001b[0m     constant_component \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2.5\u001b[39m:\n\u001b[0;32m    100\u001b[0m     constant_component \u001b[38;5;241m=\u001b[39m (math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m distance)\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;241m5.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3.0\u001b[39m \u001b[38;5;241m*\u001b[39m distance\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "predictions=[]\n",
    "for sample in X_np[700000:700500]:\n",
    "    loaded_model = torch.load(f'models/model_1.pth')\n",
    "    y_pred = loaded_model.predict(sample.reshape(1,-1))\n",
    "    predictions.append(y_pred.cpu().reshape(1))\n",
    "mse = mean_squared_error(np.array(predictions), y_trq_np[700000:700500])\n",
    "print(f\"{epoch}: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(np.array(predictions), y_trq_np[700000:700500])\n",
    "print(f\"{epoch}: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/test_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load('models/test_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= loaded_model.predict(X_np[700002:700003])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.5952]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.985207392177664"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trq_np[700002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(72)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=np.array([5,67])\n",
    "np.sum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [64, 128, 256, 512, 1048]\n",
    "repeats = 5\n",
    "pcas = [\"enabled\", \"disabled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742625, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np\n",
    "X_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_samples(train_inputs, input):\n",
    "    distances = np.linalg.norm(train_inputs - input, axis=1)\n",
    "\n",
    "    # Get the indices of the 1000 smallest distances\n",
    "    closest_indices = np.argsort(distances)[:10000]\n",
    "\n",
    "    # Select the 1000 closest samples\n",
    "    return closest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import mahalanobis\n",
    "def get_closest_samples_mahalanobis(train_inputs, input):\n",
    "    # Compute the covariance matrix of train_inputs\n",
    "    cov_matrix = np.cov(train_inputs, rowvar=False)\n",
    "\n",
    "    # Compute the inverse covariance matrix (if not singular)\n",
    "    try:\n",
    "        inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # Handle the case where the covariance matrix is singular\n",
    "        inv_cov_matrix = np.eye(train_inputs.shape[1])  # Use identity matrix as a fallback\n",
    "\n",
    "    # Compute Mahalanobis distances\n",
    "    mahalanobis_distances = []\n",
    "    for sample in train_inputs:\n",
    "        dist = mahalanobis(sample, input, inv_cov_matrix)\n",
    "        mahalanobis_distances.append(dist)\n",
    "\n",
    "    # Get the indices of the 1000 smallest distances\n",
    "    closest_indices = np.argsort(mahalanobis_distances)[:4050]\n",
    "\n",
    "    # Return the indices of the closest samples\n",
    "    return closest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\janni\\AppData\\Local\\Temp\\ipykernel_16628\\1104276301.py\", line 9, in <module>\n",
      "    model = Model(X_np_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-2)\n",
      "  File \"C:\\Projects/covnet2\\model.py\", line 19, in __init__\n",
      "    from pt.models import CovNet\n",
      "  File \"C:\\Projects/covnet2\\pt\\models.py\", line 1, in <module>\n",
      "    from botorch.models.utils.gpytorch_modules import MIN_INFERRED_NOISE_LEVEL\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\botorch\\__init__.py\", line 7, in <module>\n",
      "    import gpytorch.settings as gp_settings\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\__init__.py\", line 5, in <module>\n",
      "    import linear_operator\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\__init__.py\", line 2, in <module>\n",
      "    from . import beta_features, operators, settings, utils\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\__init__.py\", line 3, in <module>\n",
      "    from ._linear_operator import LinearOperator, to_dense\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py\", line 27, in <module>\n",
      "    from .. import settings, utils\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\__init__.py\", line 4, in <module>\n",
      "    from .contour_integral_quad import contour_integral_quad\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\contour_integral_quad.py\", line 7, in <module>\n",
      "    from .linear_cg import linear_cg\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\linear_cg.py\", line 8, in <module>\n",
      "    from .deprecation import bool_compat\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\deprecation.py\", line 13, in <module>\n",
      "    bool_compat = (torch.ones(1) > 0).dtype\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\deprecation.py:13: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  bool_compat = (torch.ones(1) > 0).dtype\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-07 to the diagonal\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m predictions\u001b[38;5;241m.\u001b[39mappend(y_pred\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     13\u001b[0m upper\u001b[38;5;241m.\u001b[39mappend(ucb\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(y_trq_np[\u001b[38;5;241m700000\u001b[39m:\u001b[38;5;241m700010\u001b[39m][i])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(mse)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m-\u001b[39mucb\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\torch\\_tensor.py:1087\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = []\n",
    "upper = []\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_np[:700000])\n",
    "X_np_scaled = scaler.transform(X_np)\n",
    "for i, test_sample in enumerate(X_np_scaled[700000:700010]):\n",
    "    indicies = get_closest_samples(X_np_scaled[:700000], test_sample)\n",
    "    model = Model(X_np_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-2)\n",
    "    model.fit(epochs=2, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    predictions.append(y_pred.to('cpu'))\n",
    "    upper.append(ucb.to('cpu'))\n",
    "    mse = mean_squared_error(np.array(y_pred.to('cpu')), np.array(y_trq_np[700000:700010][i]).reshape(1,1))\n",
    "    print(mse)\n",
    "    print(y_pred.to('cpu')-ucb.to('cpu'))\n",
    "\n",
    "predictions = np.array(predictions).reshape(-1)\n",
    "mse = mean_squared_error(predictions, y_trq_np[700000:700010])\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "upper = []\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_np[:700000])\n",
    "X_np_scaled = scaler.transform(X_np)\n",
    "for i, test_sample in enumerate(X_np_scaled[700000:700100]):\n",
    "    indicies = get_closest_samples_mahalanobis(X_np_scaled[:700000], test_sample)\n",
    "    model = Model(X_np_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "    model.fit(epochs=30, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    predictions.append(y_pred.to('cpu'))\n",
    "    upper.append(ucb.to('cpu'))\n",
    "    mse = mean_squared_error(np.array(y_pred.to('cpu')), np.array(y_trq_np[700000:700100][i]).reshape(1,1))\n",
    "    print(mse)\n",
    "    print(y_pred.to('cpu')-ucb.to('cpu'))\n",
    "\n",
    "predictions = np.array(predictions).reshape(-1)\n",
    "mse = mean_squared_error(predictions, y_trq_np[700000:700100])\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.82109832e-02, 1.53442318e+00, 2.69240206e-01, 7.41821727e-03,\n",
       "       8.39102007e-03, 4.11864508e-01, 1.17057637e+00, 7.42744247e-02,\n",
       "       9.09095602e-01, 4.03196193e-01, 9.29225487e-01, 2.73146409e-01,\n",
       "       2.22771321e-01, 2.00000000e-05, 4.28641171e-01, 6.16244775e-01,\n",
       "       5.74825217e-01, 1.95233212e-02, 7.02649719e-01, 3.66861982e-01,\n",
       "       1.47994757e+00, 2.00000000e-05, 4.33813366e-01, 7.57228132e-01,\n",
       "       1.35393295e-02, 2.59754865e-01, 1.43452497e-01, 1.47754756e-01,\n",
       "       4.19194391e-01, 2.98340375e-01])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_sample(data, n_samples):\n",
    "    n_rows = data.shape[0]\n",
    "    bootstrap_samples = []\n",
    "    for _ in range(n_samples):\n",
    "        indices = np.random.choice(n_rows, size=5000, replace=True)\n",
    "        bootstrap_sample = data[indices]\n",
    "        bootstrap_samples.append(bootstrap_sample)\n",
    "    return bootstrap_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  7.00it/s, loss=18.1, lr=1.000E-03, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05364855803823902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.06it/s, loss=5.82e+4, lr=1.000E-03, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.74193137562021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch:  90%|█████████ | 9/10 [00:01<00:00,  9.05it/s, loss=17.9, lr=1.000E-03, noise=1e-6]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.85it/s, loss=17.6, lr=1.000E-03, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10138616995632432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch:  20%|██        | 2/10 [00:00<00:00,  8.22it/s, loss=64.1, lr=1.000E-03, noise=1e-6]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.73it/s, loss=38.7, lr=1.000E-03, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08067097188221671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch:  60%|██████    | 6/10 [00:00<00:00,  8.96it/s, loss=126, lr=1.000E-03, noise=1e-6]    c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.12it/s, loss=104, lr=1.000E-03, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3055100665420039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.71it/s, loss=14.6, lr=1.000E-03, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09296046543406748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.98it/s, loss=14.3, lr=1.000E-03, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21342920915086264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch:  90%|█████████ | 9/10 [00:01<00:00,  9.04it/s, loss=8.87, lr=1.000E-03, noise=1e-6]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.90it/s, loss=8.91, lr=1.000E-03, noise=1e-6]\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06034403132676745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch:  30%|███       | 3/10 [00:00<00:00,  8.55it/s, loss=22.9, lr=1.000E-03, noise=1e-6]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.01it/s, loss=13, lr=1.000E-03, noise=1e-6] \n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18973436037912206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch:  30%|███       | 3/10 [00:00<00:00,  8.77it/s, loss=18.9, lr=1.000E-03, noise=1e-6]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 10/10 [00:01<00:00,  8.73it/s, loss=12.6, lr=1.000E-03, noise=1e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0668374973153036\n"
     ]
    }
   ],
   "source": [
    "samples = create_bootstrap_sample(np.concatenate((X_np[:700000], y_trq_np[:700000].reshape(-1,1)), axis=1),10)\n",
    "predictions = []\n",
    "for sample in samples:\n",
    "    X = sample[:,:7]\n",
    "    y = sample[:,7]\n",
    "    model = Model(X, y, noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "    model.fit(epochs=10, verbose=True)\n",
    "    y_pred, lcb, ucb = model.predict(X_np[700000:700500], pred_var=True)\n",
    "    print(mean_squared_error(np.array(y_pred.to('cpu')).reshape(-1,1), y_trq_np[700000:700500]))\n",
    "\n",
    "\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.array(predictions)\n",
    "aggregated_predictions = np.mean(all_predictions, axis=0)\n",
    "print(mean_squared_error(aggregated_predictions, y_trq_np[700000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it, loss=79.7, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=10.6, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, loss=5.62, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, loss=4.53, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, loss=3.92, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=3.51, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=3.38, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, loss=3.28, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=3.23, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=3.15, lr=1.000E-03, noise=1e-6]\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, loss=3.13, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, loss=3.11, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=3.15, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, loss=2.97, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=3.05, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, loss=2.97, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=2.9, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, loss=3.09, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, loss=2.91, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.94, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.98, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=2.83, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, loss=2.85, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, loss=2.92, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, loss=2.77, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=2.86, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.81, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=2.72, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, loss=2.79, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, loss=2.76, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=2.48, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.58, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.47, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=2.53, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, loss=2.32, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=2.25, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, loss=2.3, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, loss=2.28, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=2.19, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=2.17, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=2.16, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.24, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=2.12, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=2.18, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, loss=2.06, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.16, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=2.03, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.13, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.02, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=2.2, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=2.09, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, loss=1.97, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, loss=2.01, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, loss=2.07, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=1.95, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, loss=1.91, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=1.91, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, loss=1.93, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.89, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, loss=1.83, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=1.9, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.82, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.86, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=1.79, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, loss=1.81, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, loss=1.77, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=1.7, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=1.64, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=1.62, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, loss=1.79, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=1.63, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=1.62, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.59, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=1.58, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.72, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, loss=1.59, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, loss=1.6, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, loss=1.56, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=1.55, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, loss=1.67, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.44, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, loss=1.61, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.6, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=1.67, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.52, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, loss=1.58, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, loss=1.54, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, loss=1.47, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.51, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, loss=1.41, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, loss=1.47, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.5, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=1.46, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, loss=1.47, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, loss=1.43, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, loss=1.43, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, loss=1.43, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, loss=1.35, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, loss=1.44, lr=1.000E-03, noise=1e-6]\n",
      "Epoch: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, loss=1.41, lr=1.000E-03, noise=1e-6]\n"
     ]
    }
   ],
   "source": [
    "lowest_mse=1 \n",
    "X_valid_np = np.array(X_train[700000:])\n",
    "X_test_np = np.array(X_train[100000:100001])\n",
    "model = Model(X_np, y_trq_np, noise=False, batch_size=1024, neurons=200, learning_rate=1e-3)\n",
    "for epoch in range(100):\n",
    "    model.fit(epochs=1, verbose=True)\n",
    "    \n",
    "    # y_pred_reg_test = model.predict(X_test_np)\n",
    "    # y_pred_reg_test = y_pred_reg_test.to(\"cpu\")\n",
    "    # mse_test = mean_squared_error(y_pred_reg_test, np.array(y_trq[100000:105000]))\n",
    "    # print(mse_test)\n",
    "    # y_pred_reg = model.predict(X_valid_np)\n",
    "    # y_pred_reg = y_pred_reg.to(\"cpu\")\n",
    "    # mse = mean_squared_error(y_pred_reg, np.array(y_trq[700000:705000]))\n",
    "    # print(mse)\n",
    "    # if epoch %10 ==0 or mse<lowest_mse:\n",
    "    #     model_name= f\"models/model_{epoch}.pth\"\n",
    "    #     torch.save(model, model_name)\n",
    "    #     if mse<lowest_mse:\n",
    "    #         lowest_mse=mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = np.array(X_train[100000:101000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.661960354567126"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trq[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0186]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_reg_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in X_test_np:\n",
    "    y_pred_reg_valid = model.predict(i)\n",
    "    predictions.append(y_pred_reg_valid.to('cpu'))\n",
    "predictions = np.array(predictions).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(predictions, np.array(y_trq[100000:101000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3025.9186496036523"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10.01860018]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742625, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42625, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.2215],\n",
       "        [-3.0985],\n",
       "        [ 9.4272],\n",
       "        ...,\n",
       "        [-8.3928],\n",
       "        [ 7.6205],\n",
       "        [ 5.0785]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_reg_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_np = np.array(X_train[700000:])\n",
    "y_pred_reg_valid = model.predict(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42625"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_reg_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =np.array(predictions).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42625])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_reg_valid.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_trq_np[700000:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trq_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(np.array(y_pred_reg_valid.reshape(-1).to('cpu')), np.array(y_trq[700000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.891956202372026"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9.7287],\n",
       "        [  4.4659],\n",
       "        [ 10.9164],\n",
       "        [  1.3744],\n",
       "        [ 12.1732],\n",
       "        [ 13.6505],\n",
       "        [  8.6195],\n",
       "        [  2.6678],\n",
       "        [  0.4577],\n",
       "        [-15.0898],\n",
       "        [-11.3290],\n",
       "        [ -0.3779],\n",
       "        [ 19.3056],\n",
       "        [  8.5827],\n",
       "        [ 11.9428],\n",
       "        [ -2.1250],\n",
       "        [ -0.0356],\n",
       "        [ -3.6832],\n",
       "        [-12.5571],\n",
       "        [  6.4646],\n",
       "        [  6.2279],\n",
       "        [  5.6280],\n",
       "        [ -0.9589],\n",
       "        [ -5.8614],\n",
       "        [  6.2193],\n",
       "        [  7.6595],\n",
       "        [  6.0361],\n",
       "        [  7.6964],\n",
       "        [ -8.1492],\n",
       "        [-18.1537],\n",
       "        [ 12.7509],\n",
       "        [ -6.5269],\n",
       "        [  5.6578],\n",
       "        [  1.9772],\n",
       "        [ -1.7935],\n",
       "        [ -7.6769],\n",
       "        [ -3.1195],\n",
       "        [  2.5145],\n",
       "        [  9.0783],\n",
       "        [  3.2320],\n",
       "        [ 11.9081],\n",
       "        [ -6.0328],\n",
       "        [  7.2724],\n",
       "        [ 17.5959],\n",
       "        [  5.2186],\n",
       "        [  1.8403],\n",
       "        [ -7.5535],\n",
       "        [  2.8366],\n",
       "        [ 11.2584],\n",
       "        [ -4.7096]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_reg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02168344920155582"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_np = np.array(X_train[10000:20000])\n",
    "y_pred = model.predict(X_test_np)\n",
    "y_pred = y_pred.to(\"cpu\")\n",
    "mse = mean_squared_error(y_pred, np.array(y_trq[10000:20000]))\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23349293415623096,\n",
       " 0.1909339338111983,\n",
       " 0.007933209249155575,\n",
       " 0.029223683480669723,\n",
       " 0.03361694145177521,\n",
       " 0.10668213075885415,\n",
       " 0.030489042080994712,\n",
       " 0.015514424225184833,\n",
       " 0.016535532116858202,\n",
       " 1.2902604334861452]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\gpytorch\\likelihoods\\noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]c:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "Epoch:   1%|          | 1/100 [00:00<00:46,  2.14it/s, loss=66.6, lr=1.000E-02, noise=1e-6]c:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "Epoch: 100%|██████████| 100/100 [00:22<00:00,  4.50it/s, loss=8.59, lr=1.000E-02, noise=1e-6]\n"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    X_np, y_trq_np, noise=False, batch_size=512, neurons=50, learning_rate=1e-2\n",
    ")\n",
    "model.fit(epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Model' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m15000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Model' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "output = model(np.array(X_train[10000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.array(X_train[10000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = y_pred.to(\"cpu\")\n",
    "mse = mean_squared_error(y_pred, np.array(y_trq[10000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030111247707689363"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.320451391219264"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_np, y_trq_np)\n",
    "y_pred = lin.predict(np.array(X_train[10000:15000]))\n",
    "mse = mean_squared_error(y_pred, np.array(y_trq[10000:15000]))\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\je009447\\AppData\\Local\\miniconda3\\envs\\bayesnewton\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4961789b3c46caa3c82b561373d2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\je009447\\AppData\\Local\\miniconda3\\envs\\bayesnewton\\lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "c:\\Users\\je009447\\AppData\\Local\\miniconda3\\envs\\bayesnewton\\lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class_model = Model(\n",
    "    X_np, y_faulty_np, noise=False, batch_size=512, neurons=50, learning_rate=1e-2\n",
    ")\n",
    "class_model.fit(epochs=150, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.array(X_train[10000:15000]))\n",
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, lcb, ucb = model.predict(np.array(X_train[10000:15000]), pred_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.],\n",
       "        [-6.],\n",
       "        [-4.],\n",
       "        ...,\n",
       "        [ 8.],\n",
       "        [14.],\n",
       "        [-4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 2\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_faulty\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m15000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m acc\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:104\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m    103\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:314\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:169\u001b[0m, in \u001b[0;36mis_multilabel\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, VisibleDeprecationWarning)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\_tensor.py:1087\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_pred, np.array(y_faulty[10000:15000]))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1910663424724587\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgboost = XGBRegressor()\n",
    "xgboost.fit(X_np, y_trq_np)\n",
    "y_pred_xg = xgboost.predict(np.array(X_train[10000:15000]))\n",
    "mse = mean_squared_error(y_pred, np.array(y_trq[10000:15000]))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trq_np.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np_class = np.concatenate((X_np, y_trq_np.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 7, got 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m xgboost \u001b[38;5;241m=\u001b[39m XGBClassifier()\n\u001b[0;32m      4\u001b[0m xgboost\u001b[38;5;241m.\u001b[39mfit(X_np, y_faulty_np)\n\u001b[1;32m----> 5\u001b[0m y_pred_xg \u001b[38;5;241m=\u001b[39m \u001b[43mxgboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m700000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m705000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_pred_xg, np\u001b[38;5;241m.\u001b[39marray(y_faulty[\u001b[38;5;241m700000\u001b[39m:\u001b[38;5;241m705000\u001b[39m]))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(acc)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\xgboost\\sklearn.py:1565\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1562\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1563\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1564\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1565\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1573\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\xgboost\\sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\cuda\\Lib\\site-packages\\xgboost\\core.py:2520\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2516\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2517\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2518\u001b[0m         )\n\u001b[0;32m   2519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m-> 2520\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2521\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2522\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2523\u001b[0m         )\n\u001b[0;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 7, got 8"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost = XGBClassifier()\n",
    "xgboost.fit(X_np, y_faulty_np)\n",
    "y_pred_xg = xgboost.predict(np.array(X_train[700000:705000]))\n",
    "acc = accuracy_score(y_pred_xg, np.array(y_faulty[700000:705000]))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train[700000:705000], np.array(y_trq[700000:705000]).reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_faulty_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_faulty[700000:705000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 8), dtype=float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train[700000:705000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "y_trq_np = np.array(y_trq)\n",
    "y_faulty_np = np.array(y_faulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgboost = XGBClassifier()\n",
    "xgboost.fit(X_np, y_faulty_np.reshape(-1,1))\n",
    "y_pred_class = xgboost.predict(np.array(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998370644672614\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = xgboost.predict(np.array(X_np))\n",
    "acc = accuracy_score(y_pred_test, y_faulty_np)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\CUDA\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:48:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best Score: 0.9922314281999688\n",
      "Test Set Accuracy: 0.9916715542521994\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='accuracy', \n",
    "                           cv=3, \n",
    "                           verbose=1, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_np[:700000], y_faulty_np[:700000])\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_np[700000:])\n",
    "accuracy = accuracy_score(y_faulty_np[700000:], y_pred)\n",
    "print(f\"Test Set Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_class = best_model.predict(np.array(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "predictions_path = os.path.join('predictions' 'y_pred_class.pkl')\n",
    "with open('predictions/y_pred_class.pkl', 'wb') as f:\n",
    "    pickle.dump(y_pred_class, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-07 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "upper = []\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_np)\n",
    "X_np_scaled = scaler.transform(X_np)\n",
    "X_test_np_scaled = scaler.transform(X_test_np)\n",
    "for i, test_sample in enumerate(X_test_np_scaled[:5000]):\n",
    "    indicies = get_closest_samples_mahalanobis(X_np_scaled, test_sample)\n",
    "    model = Model(X_np_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-2)\n",
    "    model.fit(epochs=2, verbose=False)\n",
    "    y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "    predictions.append(y_pred.to('cpu').reshape(-1))\n",
    "    upper.append(ucb.to('cpu'))\n",
    "    if i%500 ==0:\n",
    "        print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('predictions/y_pred_reg_5000.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions, f)\n",
    "\n",
    "with open('predictions/y_pred_conf_5000.pkl', 'wb') as f:\n",
    "    pickle.dump(upper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:300: GPInputWarning: You have passed data through a FixedNoiseGaussianLikelihood that did not match the size of the fixed noise, *and* you did not specify noise. This is treated as a no-op.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\janni\\anaconda3\\envs\\datascience\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-07 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "predictions3 = []\n",
    "upper3 = []\n",
    "faulty = []\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_np)\n",
    "X_np_scaled = scaler.transform(X_np)\n",
    "X_test_np_scaled = scaler.transform(X_test_np)\n",
    "for i, test_sample in enumerate(X_test_np_scaled[6192:8000]):\n",
    "    try:\n",
    "        indicies = get_closest_samples_mahalanobis(X_np_scaled, test_sample)\n",
    "        model = Model(X_np_scaled[indicies], y_trq_np[indicies], noise=False, batch_size=1024, neurons=200, learning_rate=1e-2)\n",
    "        model.fit(epochs=2, verbose=False)\n",
    "        y_pred, lcb, ucb = model.predict(test_sample, pred_var=True)\n",
    "        predictions3.append(y_pred.to('cpu').reshape(-1))\n",
    "        upper3.append(ucb.to('cpu'))\n",
    "        if i%500 ==0:\n",
    "            print(i)\n",
    "    except:\n",
    "        faulty.append(test_sample)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faulty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfaulty\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'faulty' is not defined"
     ]
    }
   ],
   "source": [
    "faulty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upper3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('predictions/y_pred_reg_8000.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions3, f)\n",
    "\n",
    "with open('predictions/y_pred_conf_8000.pkl', 'wb') as f:\n",
    "    pickle.dump(upper3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.13918631,  1.89735088, -3.53644523, -3.19939769,  5.51870315,\n",
       "        1.43063301, 16.02386305, 14.87186913,  9.8996958 , 10.25744746])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearRegression()\n",
    "lin.fit(X_np, y_trq_np)\n",
    "y_pred = lin.predict(np.array(X_train[10000:15000]))\n",
    "mse = mean_squared_error(y_pred, np.array(y_trq[10000:15000]))\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_margin = upper_bound - y_pred_reg\n",
    "se = error_margin/1.96\n",
    "# se is the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = {}\n",
    "for i in ids:\n",
    "    {\n",
    "        \"class\": y_pred_class[i - 1],\n",
    "        \"class_conf\": y_pred_class_conf[i - 1],\n",
    "        \"pdf_type\": \"norm\",\n",
    "        \"pdf_args\": {\"loc\": y_pred_reg, \"scale\": y_pred_reg_dev},\n",
    "    }\n",
    "    output_data[i] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"output.json\", \"w\") as json_file:\n",
    "    json.dump(output_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='accuracy', \n",
    "                           cv=3, \n",
    "                           verbose=1, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(exp_train,exp_yclass_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "y_pred = best_model.predict(exp_test)\n",
    "accuracy = accuracy_score(exp_yclass_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {accuracy}\")\n",
    "xgb_clf_best = xgb.XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    colsample_bytree=best_params['colsample_bytree']\n",
    ")\n",
    "\n",
    "xgb_clf_best.fit(X_np, y_faulty_np)\n",
    "y_pred_class = xgb_clf_best.predict(X_test_np)\n",
    "import pickle\n",
    "with open('predictions/class_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(y_pred_class, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesnewton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
