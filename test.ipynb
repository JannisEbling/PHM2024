{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "20000\n",
      "1\n",
      "2000\n",
      "20000\n",
      "2\n",
      "2000\n",
      "20000\n",
      "3\n",
      "2000\n",
      "20000\n",
      "4\n",
      "2000\n",
      "20000\n",
      "5\n",
      "1000\n",
      "10000\n",
      "6\n",
      "4000\n",
      "40000\n",
      "7\n",
      "2000\n",
      "20000\n",
      "8\n",
      "3000\n",
      "30000\n",
      "9\n",
      "1436\n",
      "14360\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "reg_prediction_files = ['2000', '2000_4000', '4000_6000', '6000_8000', '8000_10000', '10000_11000', '11000_15000', '15000_17000', '17000_20000', '20000_end']\n",
    "all_preds = []\n",
    "\n",
    "# Loop through each file and load the predictions\n",
    "for file in reg_prediction_files:\n",
    "    with open(f\"predictions/y_pred_reg_{file}.pkl\", \"rb\") as f:\n",
    "        reg_preds = pickle.load(f)\n",
    "        print(len(reg_preds))\n",
    "        flattened_tensor_list = [item for sublist in reg_preds for item in sublist]\n",
    "        preds = []\n",
    "        for j in range(len(flattened_tensor_list)):\n",
    "            if isinstance(flattened_tensor_list[j], bool):\n",
    "                preds.append(flattened_tensor_list[j])\n",
    "                continue\n",
    "            \n",
    "            preds.append(flattened_tensor_list[j].numpy()[0][0])\n",
    "        print(len(preds))\n",
    "        all_preds.append(preds)\n",
    "        print(len(all_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reg_preds = np.concatenate(all_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214360"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_reg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all predictions into a single array\n",
    "combined_reg_preds = np.concatenate(all_preds, axis=0)\n",
    "\n",
    "# Optionally, save the combined predictions to a new file\n",
    "with open(\"predictions/combined_reg_preds.pkl\", \"wb\") as f:\n",
    "    pickle.dump(combined_reg_preds, f)\n",
    "\n",
    "with open(\"predictions/class_predictions.pkl\", \"rb\") as f:\n",
    "    class_preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.27094227  8.93795492  8.59709037 ...  8.72924028  8.5579202\n",
      "   0.        ]\n",
      " [ 1.82612505  1.62816567  1.94056469 ...  2.50960277  1.6865316\n",
      "   1.90979697]\n",
      " [-3.33576015 -5.03238398 -4.62953495 ... -3.27101134  0.\n",
      "  -6.32220861]\n",
      " ...\n",
      " [-3.81363774 -4.65818414  0.26042204 ... -1.60947944 -4.00797423\n",
      "  -1.24212375]\n",
      " [12.55944631 12.15027597 12.16126168 ... 12.8047358  12.84917697\n",
      "  15.33892423]\n",
      " [ 6.11198372  5.95945906  0.         ...  5.76481379  6.12867991\n",
      "   5.61380804]]\n"
     ]
    }
   ],
   "source": [
    "y_preds_10 = np.array(combined_reg_preds).reshape(-1, 10)\n",
    "\n",
    "# Calculate the Z-scores\n",
    "z_scores = stats.zscore(\n",
    "    y_preds_10, axis=1\n",
    ")  # Calculate Z-scores for the entire array\n",
    "\n",
    "# Create a boolean mask where elements with |Z-score| > 3 are True\n",
    "outliers_mask = np.abs(z_scores) > 2.5\n",
    "\n",
    "# Convert outliers to False\n",
    "y_preds_10[outliers_mask] = False\n",
    "\n",
    "print(y_preds_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21436, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janni\\AppData\\Local\\Temp\\ipykernel_19896\\1627597677.py:4: RuntimeWarning: Mean of empty slice\n",
      "  row_means = np.nanmean(y_preds_10.astype(float), axis=1)\n",
      "c:\\Users\\janni\\anaconda3\\envs\\NUMP\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "y_preds_10[y_preds_10 == 0] = None\n",
    "\n",
    "# Calculate the mean of each row, ignoring None values (use np.nanmean)\n",
    "row_means = np.nanmean(y_preds_10.astype(float), axis=1)\n",
    "row_stds = np.nanstd(y_preds_10.astype(float), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = {}\n",
    "for i in range(len(row_means)):\n",
    "\n",
    "    output_data[i] = {\n",
    "            #\"class\": np.int64(class_preds[i]),\n",
    "            \"class_conf\": 1,\n",
    "            \"pdf_type\": \"norm\",\n",
    "            \"pdf_args\": {\"loc\": row_means[i], \"scale\": row_stds[i]},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moutput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_conf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "output_data[0][\"class_conf\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "json_file_path = \"submission.jso\"\n",
    "\n",
    "# Save dictionary to JSON file\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(output_data, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django_outlierdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
